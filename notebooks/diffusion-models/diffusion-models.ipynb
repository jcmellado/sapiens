{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bf7343-7474-4b50-a457-ea32cc84f017",
   "metadata": {},
   "source": [
    "# Diffusion Probabilistic Models\n",
    "\n",
    "Revisión informal de \"_Deep Unsupervised Learning using Nonequilibrium Thermodynamics_\".\n",
    "\n",
    "Técnica publicada en marzo de 2015.\n",
    "\n",
    "- [https://arxiv.org/pdf/1503.03585](https://arxiv.org/pdf/1503.03585)\n",
    "\n",
    "Trabajo fundacional que estableció las bases teóricas de los modelos generativos de difusión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671bcdc4-9802-4545-aada-b33b41552caa",
   "metadata": {},
   "source": [
    "## 1. Arquitectura\n",
    "\n",
    "Un modelo generativo genera valores que siguen una determinada distribución de probabilidad de referencia dada. El reto es que el modelo sea capaz de generar cualquier distribución dada, por muy compleja que sea.\n",
    "\n",
    "Los modelos generativos de difusión utilizan una técnica basada en convertir la distribución de referencia compleja en otra más sencilla. Y lo hacen aplicando ruido gradualmente a los datos originales hasta que tengan una distribución sencilla.\n",
    "\n",
    "```\n",
    "Data ─> Diffusion ─> Noise\n",
    "```\n",
    "\n",
    "Y enseñando al modelo a revertir el proceso, generando datos estructurados con la distribución compleja a partir de ruido con una distribución sencilla.\n",
    "\n",
    "```\n",
    "Noise ─> Inverse Diffusion ─> Data\n",
    "```\n",
    "\n",
    "El _paper_ detalla un proceso de difusión, uno de difusión inversa, y cómo utilizar ambos procesos para entrenar un modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54aa2a-c95e-4252-8004-ade3160a7c42",
   "metadata": {},
   "source": [
    "## 2. Diffusion\n",
    "\n",
    "El proceso de difusión destruye gradualmente la estructura de los datos originales añadiendo ruido de manera progresiva en $T$ pasos.\n",
    "\n",
    "```\n",
    "Data ─> T x Diffusion ─> Noise\n",
    "```\n",
    "\n",
    "El proceso se presenta de manera formal, y posteriormente se aclara cómo y cuándo aplicarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d556d-7d78-47e1-9ad7-91cb460adde2",
   "metadata": {},
   "source": [
    "### 2.1. Forward Trajectory\n",
    "\n",
    "El marco teórico del _paper_ parte de una distribución de probabilidad compleja.\n",
    "\n",
    "- $ q(\\mathbf{x}^{(0)}) $\n",
    "\n",
    "Con el objetivo de convertirla en otra distribución más sencilla.\n",
    "\n",
    "- $ \\pi(\\mathbf{y}) $\n",
    "\n",
    "Mediante aplicaciones sucesivas de un núcleo de difusión de Markov.\n",
    "\n",
    "- $ \\mathcal{T}_{\\pi}(\\mathbf{y} \\mid \\mathbf{y'} ; \\beta) $\n",
    "\n",
    "La idea es que se puede avanzar desde la distribución original hasta la deseada (_Forward Trajectory_) en un número finito de pasos.\n",
    "\n",
    "- $ q \\left( \\mathbf{x}^{(0 \\ldots T)} \\right) = q \\left( \\mathbf{x}^{(0)} \\right) \\prod\\limits_{t=1}^T q \\left( \\mathbf{x}^{(t)} \\mid \\mathbf{x}^{(t-1)} \\right) $\n",
    "\n",
    "Estando los pasos para transicionar de una distribución a otra definidos por el núcleo de difusión de Markov.\n",
    "\n",
    "- $ q \\left( \\mathbf{x}^{(t)} \\mid \\mathbf{x}^{(t-1)} \\right) = \\mathcal{T}_{\\pi} \\left(\\mathbf{x}^{(t)} \\mid \\mathbf{x}^{(t-1)} ; \\beta_t \\right) $\n",
    "\n",
    "Y siendo la distribución deseada una distribución _estacionaria_, que una vez alcanzada no se abandona (condición de equilibrio).\n",
    "\n",
    "- $ \\pi(\\mathbf{y}) = \\displaystyle \\int \\pi(\\mathbf{y'}) \\mathcal{T}_{\\pi} (\\mathbf{y} \\mid \\mathbf{y'} ; \\beta) d\\mathbf{y'} $\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $\\mathbf{x}^{(0)}$: los datos de partida, o estado inicial, por ejemplo una imagen.\n",
    "\n",
    "- $q(\\mathbf{x}^{(0)})$: la distribución de probabilidad de los datos de partida, habitualmente compleja y analíticamente intratable.\n",
    "\n",
    "- $q \\left( \\mathbf{x}^{(t)} \\mid \\mathbf{x}^{(t-1)} \\right)$: la probabilidad de transicionar al estado $\\mathbf{x}^{(t)}$ desde el estado anterior $\\mathbf{x}^{(t-1)}$.\n",
    "\n",
    "- $\\pi(\\mathbf{y})$: la distribución de probabilidad deseada, más sencilla y tratable que la de partida, como por ejemplo una gaussiana con matriz de covarianza igual a la identidad (gaussiana isótropa).\n",
    "\n",
    "- $\\mathcal{T}_{\\pi}(\\mathbf{y} \\mid \\mathbf{y'} ; \\beta)$: el núcleo de difusión que define la probabilidad de pasar de un estado a otro en un solo paso.\n",
    "\n",
    "- $\\beta_t$: la tasa de difusión, o cantidad de ruido, aplicada en el paso $t$.\n",
    "\n",
    "- $q \\left( \\mathbf{x}^{(0 \\ldots T)} \\right)$: la probabilidad conjunta de la trayectoria completa, desde el estado inicial hasta el final, en $T$ pasos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0513ad84-6965-45a6-bbe2-06af6a4a7510",
   "metadata": {},
   "source": [
    "### 2.2. Distribución Estacionaria\n",
    "\n",
    "Antes de continuar, es interesante detenerse en la expresión de la distribución estacionaria.\n",
    "\n",
    "- $ \\pi(\\mathbf{y}) = \\displaystyle \\int \\pi(\\mathbf{y'}) \\mathcal{T}_{\\pi} (\\mathbf{y} \\mid \\mathbf{y'} ; \\beta) d\\mathbf{y'} $\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $\\pi(\\mathbf{y})$: la probabilidad de que el sistema se encuentre en el estado $\\mathbf{y}$.\n",
    "\n",
    "- $\\pi(\\mathbf{y'})$: la probabilidad de que el sistema se encuentre en cualquier otro estado $\\mathbf{y'}$.\n",
    "\n",
    "- $\\mathcal{T}_{\\pi} (\\mathbf{y} \\mid \\mathbf{y'} ; \\beta)$: la probabilidad de transicionar del estado $\\mathbf{y'}$ al estado $\\mathbf{y}$.\n",
    "\n",
    "- $\\pi(\\mathbf{y'}) \\mathcal{T}_{\\pi} (\\mathbf{y} \\mid \\mathbf{y'} ; \\beta)$: la probabilidad conjunta de que el sistema se encuentre en el estado $\\mathbf{y'}$ y transicione al estado $\\mathbf{y}$.\n",
    "\n",
    "- $\\displaystyle \\int \\ldots d\\mathbf{y'}$: la integral suma estas probabilidades conjuntas sobre todos los posibles estados de partida $\\mathbf{y'}$.\n",
    "\n",
    "Es decir, la probabilidad de que el sistema se encuentre en el estado $\\mathbf{y}$ es igual a la probabilidad total de que transicione a dicho estado desde cualquier otro estado posible.\n",
    "\n",
    "La distribución de probabilidad no cambia después de transicionar. El sistema ha alcanzado un estado de equilibrio y la distribución $\\pi$ se mantiene estable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cbc6bc-f35c-492f-9027-a3e2264e07e8",
   "metadata": {},
   "source": [
    "### 2.3. Diffusion Kernel\n",
    "\n",
    "En el proceso de difusión (_Forward Trajectory_) se utiliza un núcleo de difusión concreto con una forma predefinida.\n",
    "\n",
    "En un apéndice del _paper_ se muestran las ecuaciones utilizadas para los experimentos asumiendo que la distribución estacionaria es gaussiana, con media cero y covarianza igual a la identidad.\n",
    "\n",
    "- $ \\pi \\left( \\mathbf{x}^{(T)} \\right) = \\mathcal{N} \\left( \\mathbf{x}^{(T)}; \\mathbf{0}, \\mathbf{I} \\right) $\n",
    "\n",
    "De forma que el núcleo de difusión es también una distribución gaussiana.\n",
    "\n",
    "- $ q \\left( \\mathbf{x}^{(t)} \\mid \\mathbf{x}^{(t-1)} \\right) = \\mathcal{N} \\left( \\mathbf{x}^{(t)}; \\mathbf{x}^{(t-1)} \\sqrt{1 - \\beta_t}, \\mathbf{I} \\beta_t \\right) $\n",
    "\n",
    "El núcleo añade ruido progresivamente, aumentando la covarianza por $\\beta_t$. Y disminuye la influencia de la señal original progresivamente, atenuando la media por $\\sqrt{1 - \\beta_t}$.\n",
    "\n",
    "Si $\\beta_t$ es cercano a cero la señal original se mantiene en gran medida. Si es cercano a uno se atenúa casi completamente y lo que queda principalmente es ruido gaussiano.\n",
    "\n",
    "En el apéndice del _paper_ se incluyen también las ecuaciones para una distribución binomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8addc3-72eb-4148-a63c-eacf1aff0e51",
   "metadata": {},
   "source": [
    "### 2.4. Diffusion Rates\n",
    "\n",
    "En cada paso del proceso de difusión se aplica una tasa de difusión $\\beta_t$ distinta, indicando la cantidad de ruido a añadir en cada paso $t$.\n",
    "\n",
    "En el _paper_ se sugiere que estos valores pueden ser aprendidos, pero también pueden ser fijos.\n",
    "\n",
    "Propone un esquema sencillo para las distribuciones binomiales, que también debería funcionar para las gaussianas.\n",
    "\n",
    "- $ \\beta_t = \\dfrac{1}{T - t + 1} $\n",
    "\n",
    "Lo que genera una secuencia de valores fijos desde $1$ hasta $T$.\n",
    "\n",
    "- $ \\dfrac{1}{T}$, $\\dfrac{1}{T -1}$, $\\dfrac{1}{T -2}$, $\\ldots$, $1 $\n",
    "\n",
    "Empieza con un valor pequeño que se va incrementando en cada paso $t$ hastar llegar a $1$ en el último paso $T$.\n",
    "\n",
    "Lo que significa que se añade poco ruido al principio y mucho más en los pasos finales del proceso de difusión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced63132-5927-493f-bfc5-89066b826dfe",
   "metadata": {},
   "source": [
    "## 3. Inverse Diffusion\n",
    "\n",
    "El proceso de difusión inversa genera valores que siguen la estructura de los datos originales a partir de ruido en $T$ pasos.\n",
    "\n",
    "```\n",
    "Noise ─> T x Inverse Diffusion ─> Data\n",
    "```\n",
    "\n",
    "El proceso se presenta de manera formal, y posteriormente se aclara cómo entrenar un modelo para que lo aprenda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a322552-3be4-45d4-b64b-063316aec8ff",
   "metadata": {},
   "source": [
    "### 3.1. Reverse Trajectory\n",
    "\n",
    "La idea es calcular una nueva distribución de probabilidad que sea igual que la estacionaria para el último estado de la cadena.\n",
    "\n",
    "- $ p \\left( \\mathbf{x}^{(T)}\\right ) = \\pi \\left( \\mathbf{x}^{(T)} \\right) $\n",
    "\n",
    "Y que permita retroceder desde la distribución estacionaria hasta la original (_Reverse Trajectory_) en el mismo número de pasos.\n",
    "\n",
    "- $ p \\left( \\mathbf{x}^{(0 \\ldots T)} \\right) = p \\left( \\mathbf{x}^{(T)} \\right) \\prod\\limits_{t=1}^T p \\left( \\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)} \\right) $\n",
    "\n",
    "Siendo la probabilidad de transición inversa la que el modelo debe aprender.\n",
    "\n",
    "- $ p \\left( \\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)} \\right) $\n",
    "\n",
    "El problema es que esta distribución es computacionacionalmente intratable. Requiere integrar sobre todas las distribuciones de datos originales. Por lo que el _paper_ propone entrenar un modelo que aprenda a aproximarla.\n",
    "\n",
    "Y además demuestra que la transición inversa tiene la misma forma gaussiana que la transición directa, si se toman pasos de difusión $\\beta_t$ suficientemente pequeños. Lo que permite diseñar un modelo que aprenda una distribución gaussiana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650b672-0448-4d25-aef9-3fd6d34671c3",
   "metadata": {},
   "source": [
    "### 3.2. Diffusion Kernel\n",
    "\n",
    "El núcleo de difusión inversa es el que el modelo debe aprender para revertir el proceso de difusión paso a paso.\n",
    "\n",
    "Se parametriza como una distribución gaussiana, donde la media y la covarianza son aprendidas por el modelo.\n",
    "\n",
    "- $ p \\left( \\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)} \\right) = \\mathcal{N} \\left( \\mathbf{x}^{(t-1)}; \\mathbf{f}_{\\mu} (\\mathbf{x}^{(t)}, t), \\mathbf{f}_{\\Sigma} (\\mathbf{x}^{(t)}, t) \\right) $\n",
    "\n",
    "Las funciones $\\mathbf{f}_{\\mu}$ y $\\mathbf{f}_{\\Sigma}$ representan el modelo, que aprende a predecir los parámetros de la gaussiana a partir del dato con ruido $\\mathbf{x}^{(t)}$ y el paso de tiempo $t$.\n",
    "\n",
    "En un apéndice del _paper_ se incluyen también las ecuaciones para una distribución binomial."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a85968f-cefe-4572-8c6d-3ea738ba3a0f",
   "metadata": {},
   "source": [
    "## 4. Entrenamiento\n",
    "\n",
    "Una vez presentados formalmente los procesos de difusión y difusión inversa, queda la tarea de diseñar la forma de entrenar un modelo utilizando ambos procesos.\n",
    "\n",
    "Se plantea qué muestras utilizar para el entrenamiento, con qué compararlas, y cómo definir una función de pérdida óptima que mida la bondad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c80c4a0-97ca-4141-b3a3-847724b44e00",
   "metadata": {},
   "source": [
    "### 4.1. Esquema General\n",
    "\n",
    "```\n",
    "Input ─> Model ─> Output\n",
    "```\n",
    "\n",
    "Entradas:\n",
    "\n",
    "- $\\mathbf{x}^{(t)}$: una muestra de datos con ruido, correspondiente al paso de tiempo $t$, con dimensiones acorde a la naturaleza de los datos sobre los que se realice el entrenamiento.\n",
    "\n",
    "- $t$: el paso de tiempo actual, un valor escalar entre $1$ y $T$.\n",
    "\n",
    "Salidas:\n",
    "\n",
    "- $\\mathbf{f}_{\\mu} (\\mathbf{x}^{(t)}, t)$: media de la distribución de probabilidad estimada por el modelo, con las mismas dimensiones que la entrada $\\mathbf{x}^{(t)}$.\n",
    "\n",
    "- $\\mathbf{f}_{\\Sigma} (\\mathbf{x}^{(t)}, t)$: covarianza de la distribución de probabilidad estimada por el modelo, representada por un vector, para covarianza diagonal, o un escalar, para varianza isótropa.\n",
    "\n",
    "La arquitectura específica de la red es indiferente, pudiéndose utilizar aquella que mejor se adapte a la naturaleza de los datos sobre los que se realiza el entrenamiento. Desarrollos posteriores han mejorado la forma original propuesta de diseñar y entrenar la red."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef594d1a-32fe-4974-80ac-baacaa5bed5b",
   "metadata": {},
   "source": [
    "### 4.2. Noised Samples\n",
    "\n",
    "En este punto se plantea \"_¿qué muestras utilizar para el entrenamiento?_\".\n",
    "\n",
    "```\n",
    "Input ─> Difussion ─> Model ─> Output\n",
    "```\n",
    "\n",
    "El modelo se entrena con muestras del _dataset_ de entrenamiento a las que se le aplica el proceso de difusión.\n",
    "\n",
    "- Se toma una muestra $\\mathbf{x}^{(0)}$ del _dataset_.\n",
    "\n",
    "- Se genera un número aleatorio $t$ entre $1$ y $T$ que representa un paso de tiempo.\n",
    "\n",
    "- Y se genera la muestra $\\mathbf{x}^{(t)}$ aplicando el proceso de difusión a $\\mathbf{x}^{(0)}$ hasta el paso $t$.\n",
    "\n",
    "Dependiendo de la arquitectura de la red, las tasas de difusión $\\beta$ pueden ser fijas, o aprendidas por el modelo.\n",
    "\n",
    "```python\n",
    "t = rand(1, T)\n",
    "\n",
    "x_t = noised_sample(x_0, t, betas)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae0cca2-d6cd-4bd7-a5a0-e92f98e3ec42",
   "metadata": {},
   "source": [
    "### 4.3. Reparameterization Trick\n",
    "\n",
    "En este punto se plantea \"_¿hay una forma eficiente de aplicar ruido a las muestras de entrada?_\".\n",
    "\n",
    "```\n",
    "Input ─> Reparameterization Trick ─> Model ─> Output\n",
    "```\n",
    "\n",
    "Para calcular $\\mathbf{x}^{(t)}$ desde $\\mathbf{x}^{(0)}$ hay que aplicar el núcleo de difusión $t$ veces de forma iterativa, lo que puede ser computacionalmente ineficiente.\n",
    "\n",
    "Afortunadamente, una propiedad de las distribuciones gaussianas es que la suma de varias de ellas es también una gaussiana.\n",
    "\n",
    "Una muestra con ruido $\\mathbf{x}^{(t)}$ se puede expresar en función de la muestra original $\\mathbf{x}^{(0)}$ y un **único** ruido gaussiano $\\boldsymbol{\\epsilon}$.\n",
    "\n",
    "- $ \\mathbf{x}^{(t)} = \\sqrt{\\bar\\alpha_t} \\mathbf{x}^{(0)} + \\sqrt{1 - \\bar\\alpha_t} \\boldsymbol{\\epsilon} $\n",
    "\n",
    "Siendo $\\bar{\\alpha}_t$ el producto acumulado de $(1 - \\beta_i)$ hasta el tiempo $t$.\n",
    "\n",
    "- $ \\alpha_t = 1 - \\beta_t $\n",
    "\n",
    "- $ \\bar\\alpha_t = \\prod\\limits_{i=1}^{t} \\alpha_i $\n",
    "\n",
    "Si $\\beta_t$ es la cantidad de ruido que se añade en cada paso, $\\alpha_t$ representa la cantidad de la señal que se conserva.\n",
    "\n",
    "Lo que quiere decir todo esto, es que durante el entrenamiento no se toman las muestras del _dataset_ y se itera sobre ellas aplicando el núcleo de difusión un número $t$ de pasos deseados.\n",
    "\n",
    "```python\n",
    "x_t = x_0\n",
    "\n",
    "for i in [1..t]:\n",
    "  mean = sqrt(1 - betas[i])\n",
    "  std = sqrt(betas[i])\n",
    "  eps = randn()\n",
    "\n",
    "  x_t = x_t * mean + std * eps\n",
    "```\n",
    "\n",
    "Lo que se hace es aplicar directamente el _reparameterization trick_ y de una sola vez calcular el resultado para el paso $t$ deseado.\n",
    "\n",
    "```python\n",
    "alpha_bar_t = cumprod(1 - betas)[t]\n",
    "eps = randn()\n",
    "\n",
    "x_t = sqrt(alpha_bar_t) * x_0 + sqrt(1 - alpha_bar_t) * eps\n",
    "```\n",
    "\n",
    "Los valores $\\beta_t$ y $\\bar\\alpha_t$ se pueden precalcular, lo que hace el entrenamiento computacionalmente factible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656875f0-4c56-49ec-aa85-28a677ef8b15",
   "metadata": {},
   "source": [
    "### 4.4. Ground Truth\n",
    "\n",
    "En este punto se plantea \"_¿qué valores utilizar para comprobar cuan buenas son las predicciones del modelo?_\".\n",
    "\n",
    "```\n",
    "Input ─> Reparameterization Trick ─> Model ─> Output ─> vs <─ Ground Truth\n",
    "```\n",
    "\n",
    "Lo que el modelo debe aprender es el proceso de difusión inversa, es decir, la probabilidad de transicionar al estado $\\mathbf{x}^{(t-1)}$ desde el estado $\\mathbf{x}^{(t)}$.\n",
    "\n",
    "- $ p \\left( \\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)} \\right) $\n",
    "\n",
    "Y lo que se plantea es comprobar la bondad de las predicciones del modelo utilizando una distribución _posterior_ como _verdad fundamental_ (_Ground Truth_).\n",
    "\n",
    "La probabilidad \"_verdadera_\" de llegar al estado $\\mathbf{x}^{(t-1)}$ desde el estado $\\mathbf{x}^{(t)}$ conociendo el estado inicial $\\mathbf{x}^{(0)}$.\n",
    "\n",
    "- $ q \\left( \\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)}, \\mathbf{x}^{(0)} \\right) $\n",
    "\n",
    "El modelo no conoce el estado inicial, es lo que aprende a predecir, por lo que esta distribución posterior es óptima para medir la bondad del modelo. Guía al modelo para que sea capaz de predecir cómo es la distribución original de los datos.\n",
    "\n",
    "Distribución que según el _paper_ resulta ser una gaussiana con media:\n",
    "\n",
    "- $ \\bar{\\mu}_t(\\mathbf{x}^{(t)}, \\mathbf{x}^{(0)}) = \\dfrac{\\sqrt{\\bar\\alpha_{t-1}} \\beta_t}{1 - \\bar{\\alpha}_t} \\mathbf{x}^{(0)} + \\dfrac{\\sqrt{\\alpha_t} (1 - \\bar\\alpha_{t-1})}{1 - \\bar\\alpha_t} \\mathbf{x}^{(t)} $\n",
    "\n",
    "Y varianza:\n",
    "\n",
    "- $ \\bar{\\beta}_t = \\dfrac{1 - \\bar\\alpha_{t-1}}{1 - \\bar\\alpha_t} \\beta_t $\n",
    "\n",
    "Es decir, que se pueden tomar los valores del _dataset_, aplicarles el proceso de difusión de forma sencilla utilizando el _reparameterization trick_, y calcular a partir de ellos también de forma sencilla la media y varianza verdaderas para dichos valores.\n",
    "\n",
    "```python\n",
    "true_mean = (sqrt(alpha_bar_t_minus_1) * beta_t * x_0 +  sqrt(alpha_t) * (1 - alpha_bar_t_minus_1) * x_t) / (1 - alpha_bar_t)\n",
    "\n",
    "true_variance = ((1 - alpha_bar_t_minus_1) * beta_t) / (1 - alpha_bar_t)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756505c-eeb5-4bca-9df0-48a24005e911",
   "metadata": {},
   "source": [
    "### 4.5. Loss Function\n",
    "\n",
    "En este punto se plantea \"_¿qué función de pérdida utilizar para comparar los valores esperados con los obtenidos?_\".\n",
    "\n",
    "```\n",
    "Input ─> Reparameterization Trick ─> Model ─> Output ─> Loss Function <─ Ground Truth\n",
    "```\n",
    "\n",
    "El objetivo es que la distribución predicha por el modelo:\n",
    "\n",
    "- $ p \\left( \\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)} \\right) $\n",
    "\n",
    "Sea lo más parecida posible a la distribución _verdadera_:\n",
    "\n",
    "- $ q(\\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)}, \\mathbf{x}^{(0)}) $\n",
    "\n",
    "Para medir la diferencia entre las dos probabilidades se utiliza la _Divergencia KL_ (_Kullback–Leibler Divergence_) como función de pérdida.\n",
    "\n",
    "- $ D_{KL}(P \\Vert Q) = \\displaystyle \\sum\\limits_{x \\in \\mathcal{X}} P(x) log \\dfrac{P(x)}{Q(x)} $\n",
    "\n",
    "Siendo $P$ la distribución verdadera y $Q$ la distribución aprendida (exactamente la nomenclatura contraria que utiliza el _paper_).\n",
    "\n",
    "- $ L_t = D_{KL}(q(\\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)}, \\mathbf{x}^{(0)}) \\Vert p(\\mathbf{x}^{(t-1)} \\mid \\mathbf{x}^{(t)})) $\n",
    "\n",
    "Y lo importante es que se demuestra, que para distribuciones gaussianas, la _Divergencia KL_ tiene una solución analítica y puede por tanto calcularse.\n",
    "\n",
    "```python\n",
    "f_mu, f_sigma = model(x_t, t)\n",
    "\n",
    "q = Normal(true_mean, sqrt(true_variance))\n",
    "p = Normal(f_mu, sqrt(f_sigma))\n",
    "\n",
    "loss = mean(sum(kl_divergence(q, p)))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
