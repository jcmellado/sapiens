{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e2d9be-1221-4afe-9fcc-e86d0ca32403",
   "metadata": {},
   "source": [
    "# Transformers - Arquitectura\n",
    "\n",
    "Análisis de la arquitectura _Transformer_ propuesta originalmente en el _paper_ seminal \"_Attention Is All You Need_\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9580dab8-bd4a-4509-b015-963469c00ce9",
   "metadata": {},
   "source": [
    "## 1. Transformer\n",
    "\n",
    "Un _transformer_ es un modelo de red neuronal que procesa una secuencia de entrada y genera una secuencia de salida.\n",
    "\n",
    "```\n",
    "Input ─> Output\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdbe2a2-9ae4-4f60-9396-320c862a40fe",
   "metadata": {},
   "source": [
    "### 1.1. Encoder-Decoder\n",
    "\n",
    "El modelo tiene dos componentes.\n",
    "\n",
    "```\n",
    "Input ─> Encoder ─> Decoder ─> Output\n",
    "```\n",
    "\n",
    "El _encoder_ procesa la secuencia de entrada capturando las relaciones entre sus elementos.\n",
    "\n",
    "El _decoder_ produce la secuencia de salida, elemento a elemento, apoyándose en la información capturada por el encoder y los propios elementos que va generando.\n",
    "\n",
    "La arquitectura fue desarrollada originalmente en el ámbito del procesamiento del lenguaje natural para la traducción de textos de un idioma a otro. Es habitual entenderla como una red neuronal que procesa un texto y genera otro, palabra a palabra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084ecbd8-7112-4915-8f71-29f872aacc66",
   "metadata": {},
   "source": [
    "## 2. Input\n",
    "\n",
    "El texto de entrada se procesa en dos capas antes de introducirlo en el encoder.\n",
    "\n",
    "```\n",
    "Input ─> Embedding -> PE ─> Encoder ─> Decoder ─> Output\n",
    "```\n",
    "\n",
    "La capa de _embedding_ convierte un texto arbitrario de entrada en un formato numérico que permite su procesamiento por parte de la red.\n",
    "\n",
    "La capa de _positional encoding_ enriquece el texto original con información adicional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf77c5b-d85d-4baa-a805-bfbe8ad23327",
   "metadata": {},
   "source": [
    "### 2.1. Tokens\n",
    "\n",
    "El texto original de entrada es procesado por un componente ajeno a la red llamado _tokenizer_.\n",
    "\n",
    "Un _tokenizer_ trabaja con un vocabulario de $V$ elementos distintos. Donde cada elemento del vocabulario se conoce como _token_.\n",
    "\n",
    "$ \\begin{array}{c|l}\n",
    "\\text{Token} & \\text{Word}\n",
    "\\\\ \\hline 1 & \\text{casa}\n",
    "\\\\ 2 & \\text{árbol}\n",
    "\\\\ 3 & \\text{mesa}\n",
    "\\\\ \\vdots & \\vdots\n",
    "\\\\ V & \\text{perro}\n",
    "\\end{array} $\n",
    "\n",
    "El _tokenizer_ convierte el texto plano de entrada en una secuencia de _tokens_. De forma que la entrada a la red es una secuencia de _tokens_ de longitud $n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f02a62-f2ea-4268-b71d-12a9cdb09650",
   "metadata": {},
   "source": [
    "### 2.2. Embeddings\n",
    "\n",
    "Un _token_ se representa mediante un _embedding_.\n",
    "\n",
    "Un _embedding_ es un vector numérico de tamaño $d$.\n",
    "\n",
    "$ \\begin{array}{c|l|l}\n",
    "\\text{Token} & \\text{Word} & \\text{Embedding}\n",
    "\\\\ \\hline 1 & \\text{casa} & [e^1_1, e^1_2, \\ldots, e^1_d]\n",
    "\\\\ 2 & \\text{árbol} & [e^2_1, e^2_2, \\ldots, e^2_d]\n",
    "\\\\ 3 & \\text{mesa} & [e^3_1, e^3_2, \\ldots, e^3_d]\n",
    "\\\\ \\vdots & \\vdots & \\vdots\n",
    "\\\\ V & \\text{perro} & [e^V_1, e^V_2, \\ldots, e^V_d]\n",
    "\\end{array} $\n",
    "\n",
    "La primera capa de la red convierte cada _token_ de entrada en su correspondiente _embedding_.\n",
    "\n",
    "La capa tiene una matriz de pesos $W_E$, inicializada y actualizada durante el entrenamiento de la red neuronal.\n",
    "\n",
    "- $ W_E = \\begin{bmatrix}\n",
    "e^1_1 & e^1_2 & \\ldots & e^1_d\n",
    "\\\\ e^2_1 & e^2_2 & \\ldots & e^2_d\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ e^V_1 & e^V_2 & \\ldots & e^V_d\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Cada fila de la matriz es un _embedding_. De forma que la fila $i$ representa el _embedding_ del ordinal del token $T_i$.\n",
    "\n",
    "La salida de esta capa es una secuencia $X$ de _embeddings_ que se representa como una matriz de $n$ filas por $d$ columnas, donde cada fila corresponde a un _token_ representado por su correspondiente _embedding_.\n",
    "\n",
    "- $ X = \\begin{bmatrix}\n",
    "W_E[T_1]\n",
    "\\\\ W_E[T_2]\n",
    "\\\\ \\vdots\n",
    "\\\\ W_E[T_n]\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,d}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "En el _paper_ original los _embeddings_ tienen un tamaño de 512.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ W_E \\in \\mathbb{R}^{V \\times d} $\n",
    "\n",
    "- $ X \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0375682f-25ba-4360-a60d-506790f90c88",
   "metadata": {},
   "source": [
    "### 2.3. Positional Encoding (PE)\n",
    "\n",
    "Esta capa enriquece los _embeddings_ con información que depende de la posición relativa que ocupan dentro de la secuencia de entrada.\n",
    "\n",
    "Se aplica una función $\\operatorname{PE}(i, j)$ que se evalúa para cada par $(i, j)$ donde $i = 0, 1, \\ldots, n - 1$ y $j = 0, 1, \\ldots, d - 1$.\n",
    "\n",
    "Si $j$ es par se aplica una función seno, y si es impar una función coseno.\n",
    "\n",
    "- $ \\operatorname{PE}(i, j) = \\begin{cases} \n",
    "\\sin\\left( \\dfrac{i}{10000^{j/d}} \\right), & \\text{si } j \\text{ es par} \\\\\n",
    "\\cos\\left( \\dfrac{i}{10000^{(j-1)/d}} \\right), & \\text{si } j \\text{ es impar}\n",
    "\\end{cases} $\n",
    "\n",
    "Por convención, se considera que los índices empiezan por cero, en vez de por uno como suele ser habitual en la notación matemática.\n",
    "\n",
    "La función no depende del contenido de la entrada, sólo de la posición de los _tokens_ y el tamaño de los _embeddings_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c478cc7c-5a8a-49a7-8976-6cc8df9b21fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_positional_encoding():\n",
    "  n = 16\n",
    "  d = 64\n",
    "\n",
    "  i = np.arange(n)[:, np.newaxis]\n",
    "  j = np.arange(d)[np.newaxis, :]\n",
    "\n",
    "  PE = np.zeros((n, d))\n",
    "  PE[:, 0::2] = np.sin(i / 10000**(j[:, 0::2]/d))\n",
    "  PE[:, 1::2] = np.cos(i / 10000**((j[:, 1::2] - 1)/d))\n",
    "\n",
    "  plt.figure(figsize=(14, 6))\n",
    "  im = plt.imshow(PE, aspect='auto')\n",
    "  plt.xlabel(\"Dimensión del embedding (j)\")\n",
    "  plt.ylabel(\"Posición del token (i)\")\n",
    "  plt.title(\"Positional Encoding - seno en dimensiones pares y coseno en dimensiones impares\")\n",
    "  plt.colorbar(im)\n",
    "  plt.show()\n",
    "\n",
    "draw_positional_encoding()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef871b-1bf5-426b-8f8f-2ca421a6fdb2",
   "metadata": {},
   "source": [
    "La gráfica muestra que a cada _token_ se le asigna un patrón de valores único en función de su posición dentro de la secuencia de entrada. A mayor distancia entre _tokens_, mayor variación del patrón.\n",
    "\n",
    "Los _tokens_ en posiciones cercanas comparten patrones similares en sus primeras dimensiones, lo que permite capturar relaciones locales, como por ejemplo que dos _tokens_ (palabras) se presentan habitualmente juntos en una secuencia (frase). Por su parte, los _tokens_ en posiciones alejadas tienen patrones similares sólo en sus últimas dimensiones, lo que permite capturar relaciones globales, como la estructura general de una secuencia.\n",
    "\n",
    "Para enriquecer la secuencia de entrada con esta información, a los _embeddings_ de entrada se le suman los valores de la función, elemento a elemento.\n",
    "\n",
    "- $ E^1 = X + \\operatorname{PE(i, j)} = \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,d}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,d}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "\\operatorname{PE}(0, 0) & \\operatorname{PE}(0, 1) & \\ldots & \\operatorname{PE}(0, d-1)\n",
    "\\\\ \\operatorname{PE}(1, 0) & \\operatorname{PE}(1, 1) & \\ldots & \\operatorname{PE}(1, d-1)\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\operatorname{PE}(n - 1, 0) & \\operatorname{PE}(n - 1, 1) & \\ldots & \\operatorname{PE}(n - 1, d - 1)\n",
    "\\end{bmatrix}, \\quad \\text{para } i = 0, \\ldots, n-1, j = 0, \\dots, d-1 $\n",
    "\n",
    "Esta información añadida enriquece los valores transportados por la secuencia de entrada, información que se propaga junto con la señal original a través de la red, y queda accesible para todas las capas de la misma.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ X \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ E^1 \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb8b04-cb82-4902-962f-7d4741379097",
   "metadata": {},
   "source": [
    "### 3. Encoder\n",
    "\n",
    "El encoder se compone de varias capas.\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> PE ─> MHA ─> Add ─> Norm ─> FF ─> Add ─> Norm ─> Decoder ─> Output\n",
    "                         │          ↑          │         ↑\n",
    "                         └──────────┘          └─────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b49b3-d7e9-4e50-a340-6a85d0b9d328",
   "metadata": {},
   "source": [
    "### 3.1. Scaled Dot-Product Attention\n",
    "\n",
    "La primera capa del encoder utiliza el mecanismo de _atención_, por lo que es necesario realizar una breve introducción a dicho mecanismo.\n",
    "\n",
    "Esta técnica permite capturar relaciones complejas entre los _tokens_ de una secuencia.\n",
    "\n",
    "Utiliza tres matrices de pesos, $W_Q$, $W_K$, y $W_V$, inicializadas y actualizadas durante el entrenamiento.\n",
    "\n",
    "Las matrices son cuadradas, con tantas filas y columnas como dimensiones $d$ tengan los _embeddings_. \n",
    "\n",
    "- $ W_Q = \\begin{bmatrix}\n",
    "wq_{1,1} & wq_{1,2} & \\ldots & wq_{1,d}\n",
    "\\\\ wq_{2,1} & wq_{2,2} & \\ldots & wq_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ wq_{d,1} & wq_{d,2} & \\ldots & wq_{d,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ W_K = \\begin{bmatrix}\n",
    "wk_{1,1} & wk_{1,2} & \\ldots & wk_{1,d}\n",
    "\\\\ wk_{2,1} & wk_{2,2} & \\ldots & wk_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ wk_{d,1} & wk_{d,2} & \\ldots & wk_{d,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ W_V = \\begin{bmatrix}\n",
    "wv_{1,1} & wv_{1,2} & \\ldots & wv_{1,d}\n",
    "\\\\ wv_{2,1} & wv_{2,2} & \\ldots & wv_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ wv_{d,1} & wv_{d,2} & \\ldots & wv_{d,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "La matriz de entrada $E^1$ se multiplica (proyecta) por cada una de las matrices de pesos para obtener tres nuevas matrices, $Q$, $K$, y $V$.\n",
    "\n",
    "- $ Q = E^1 W_Q = \\begin{bmatrix}\n",
    "e^1_{1,1} & e^1_{1,2} & \\ldots & e^1_{1,d}\n",
    "\\\\ e^1_{2,1} & e^1_{2,2} & \\ldots & e^1_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ e^1_{n,1} & e^1_{n,2} & \\ldots & e^1_{n,d}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "wq_{1,1} & wq_{1,2} & \\ldots & wq_{1,d}\n",
    "\\\\ wq_{2,1} & wq_{2,2} & \\ldots & wq_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ wq_{d,1} & wq_{d,2} & \\ldots & wq_{d,d}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "q_{1,1} & q_{1,2} & \\ldots & q_{1,d}\n",
    "\\\\ q_{2,1} & q_{2,2} & \\ldots & q_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ q_{n,1} & q_{n,2} & \\ldots & q_{n,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ K = E^1 W_K = \\begin{bmatrix}\n",
    "e^1_{1,1} & e^1_{1,2} & \\ldots & e^1_{1,d}\n",
    "\\\\ e^1_{2,1} & e^1_{2,2} & \\ldots & e^1_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ e^1_{n,1} & e^1_{n,2} & \\ldots & e^1_{n,d}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "wk_{1,1} & wk_{1,2} & \\ldots & wk_{1,d}\n",
    "\\\\ wk_{2,1} & wk_{2,2} & \\ldots & wk_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ wk_{d,1} & wk_{d,2} & \\ldots & wk_{d,d}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "k_{1,1} & k_{1,2} & \\ldots & k_{1,d}\n",
    "\\\\ k_{2,1} & k_{2,2} & \\ldots & k_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ k_{n,1} & k_{n,2} & \\ldots & k_{n,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ V = E^1 W_V = \\begin{bmatrix}\n",
    "e^1_{1,1} & e^1_{1,2} & \\ldots & e^1_{1,d}\n",
    "\\\\ e^1_{2,1} & e^1_{2,2} & \\ldots & e^1_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ e^1_{n,1} & e^1_{n,2} & \\ldots & e^1_{n,d}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "wv_{1,1} & wv_{1,2} & \\ldots & wv_{1,d}\n",
    "\\\\ wv_{2,1} & wv_{2,2} & \\ldots & wv_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ wv_{d,1} & wv_{d,2} & \\ldots & wv_{d,d}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "v_{1,1} & v_{1,2} & \\ldots & v_{1,d}\n",
    "\\\\ v_{2,1} & v_{2,2} & \\ldots & v_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ v_{n,1} & v_{n,2} & \\ldots & v_{n,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Conceptualmente, el propósito de la matriz $Q$ (_Query_) es capturar la información que \"busca\" cada _token_. Por ejemplo, para el _token_ \"comió\", su consulta (_query_) podría ser \"¿quién realizó la acción y qué se comió?\".\n",
    "\n",
    "El propósito de la matriz $K$ (_Key_) es capturar la información que \"ofrece\" cada _token_. Por ejemplo, para el _token_ \"Juan\", su clave (_key_) podría ser \"sujeto que realiza acciones\", y para el _token_ \"manzana\", su clave podría ser \"objeto relacionado con comida\".\n",
    "\n",
    "Y el propósito de la matriz $V$ (_Value_) es capturar la información que \"transporta\" cada _token_. Por ejemplo, el valor (_value_) del _token_ \"Juan\" podría ser \"entidad con nombre propio\", y el del _token_ \"manzana\" podría ser \"objeto comestible\".\n",
    "\n",
    "Dadas estas matrices, el primer paso es calcular el producto escalar entre la información capturada para cada _token_ en la matrices de consultas y claves.\n",
    "\n",
    "- $ Q K^T = \\begin{bmatrix}\n",
    "q_{1,1} & q_{1,2} & \\ldots & q_{1,d}\n",
    "\\\\ q_{2,1} & q_{2,2} & \\ldots & q_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ q_{n,1} & q_{n,2} & \\ldots & q_{n,d}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "k_{1,1} & k_{2,1} & \\ldots & k_{n,1}\n",
    "\\\\ k_{1,2} & k_{2,2} & \\ldots & k_{n,2}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ k_{1,d} & k_{2,d} & \\ldots & k_{n,d}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\sum\\limits_{i=1}^{d} q_{1,i}k_{1,i} & \\sum\\limits_{i=1}^{d} q_{1,i}k_{2,i} & \\ldots & \\sum\\limits_{i=1}^{d} q_{1,i}k_{n,i}\n",
    "\\\\ \\sum\\limits_{i=1}^{d} q_{2,i}k_{1,i} & \\sum\\limits_{i=1}^{d} q_{2,i}k_{2,i} & \\ldots & \\sum\\limits_{i=1}^{d} q_{2,i}k_{n,i}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\sum\\limits_{i=1}^{d} q_{n,i}k_{1,i} & \\sum\\limits_{i=1}^{d} q_{n,i}k_{2,i} & \\ldots & \\sum\\limits_{i=1}^{d} q_{n,i}k_{n,i}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Recordando que el producto escalar es una medida de la similitud entre dos vectores, donde vectores muy similares generan valores altos, y vectores muy distintos generan valores bajos. El resultado del producto escalar es una matriz cuadrada de $n \\times n$, llamada matriz de _scores_, que compara todos los _tokens_ entre sí.\n",
    "\n",
    "De igual forma que hay redes que generan imágenes a partir de un texto, el objetivo del mecanismo de atención es generar esta matriz de _scores_. Durante el entrenamiento, los valores de las matrices de pesos se van ajustando para que el modelo sea capaz de calcular esta matriz de _scores_ y encontrar las relaciones entre los _tokens_.\n",
    "\n",
    "El siguiente paso es dividir por el número de dimensiones de los _embeddings_.\n",
    "\n",
    "- $ \\cfrac{Q K^T}{\\sqrt{d}} $\n",
    "\n",
    "Esta división sólo tiene el propósito de escalar los valores, para evitar que sean excesivamente grandes o pequeños, y conseguir una mejor distribución de los mismos durante el entrenamiento.\n",
    "\n",
    "A continuación se aplica la función $\\operatorname{softmax}$, fila a fila.\n",
    "\n",
    "- $ \\operatorname{softmax} \\left( \\cfrac{Q K^T}{\\sqrt{d}} \\right) $\n",
    "\n",
    "Esta función comprime valores que se encuentra dentro de un rango arbitrario al rango $[0, 1]$, de forma que la suma de cada fila sea igual a $1$, generando una distribución de probabilidad.\n",
    "\n",
    "- $ \\operatorname{softmax} \\left( \\mathbf{z} \\right)_i = \\cfrac{e^{z_i}}{\\sum\\limits_{j=1}^{d} e^{z_j}} $\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- $ \\operatorname{softmax} \\left( \\begin{bmatrix}\n",
    "1 & 2\n",
    "\\\\ 4 & 9\n",
    "\\end{bmatrix} \\right) = \\begin{bmatrix}\n",
    "\\cfrac{e^1}{e^1 + e^2} & \\cfrac{e^2}{e^1 + e^2}\n",
    "\\\\ \\cfrac{e^4}{e^4 + e^9} & \\cfrac{e^9}{e^4 + e^9}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "0,26894142 & 0,73105858\n",
    "\\\\ 0,00669285 & 0,99330715\n",
    "\\end{bmatrix} \\quad ; \\quad \n",
    "\\begin{aligned}\n",
    "0,26894142 + 0,73105858 = 1 \\\\\n",
    "0,00669285 + 0,99330715 = 1\n",
    "\\end{aligned} $\n",
    "\n",
    "Expresadas como probabilidades, queda más claro que la matriz resalta relaciones entre los distintos _tokens_. Por ejemplo, para la secuencia de entrada (frase) \"el libro está sobre la mesa\" se espera que los artículos \"el\" y \"la\" se enfoquen en los sustantivos \"libro\" y \"mesa\" respectivamente, que la preposición \"sobre\" se enfoque en la mesa, que el verbo \"está\" conecte \"mesa\" y \"libro\", y así sucesivamente.\n",
    "\n",
    "$ \\begin{array}{c|cccccc}\n",
    " & \\text{el} & \\text{libro} & \\text{está} & \\text{sobre} & \\text{la} & \\text{mesa} \\\\ \\hline\n",
    "\\text{el}    & 0.05 & 0.60 & 0.05 & 0.10 & 0.10 & 0.10 \\\\\n",
    "\\text{libro} & 0.10 & 0.40 & 0.20 & 0.15 & 0.10 & 0.05 \\\\\n",
    "\\text{está}  & 0.05 & 0.50 & 0.10 & 0.10 & 0.05 & 0.20 \\\\\n",
    "\\text{sobre} & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.50 \\\\\n",
    "\\text{la}    & 0.05 & 0.10 & 0.05 & 0.10 & 0.05 & 0.65 \\\\\n",
    "\\text{mesa}  & 0.05 & 0.05 & 0.05 & 0.60 & 0.20 & 0.05 \\\\\n",
    "\\end{array} $\n",
    "\n",
    "Y finalmente, se multiplican los _values_ de los _tokens_ por la distribución de probabilidad para obtener la matriz de atención.\n",
    "\n",
    "- $ A = \\operatorname{softmax} \\left( \\cfrac{Q K^T}{\\sqrt{d}} \\right) V = \\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & \\ldots & a_{1,d}\n",
    "\\\\ a_{2,1} & a_{2,2} & \\ldots & a_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ a_{n,1} & a_{n,2} & \\ldots & a_{n,d}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E^1 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ W_Q \\in \\mathbb{R}^{d \\times d} $\n",
    "\n",
    "- $ W_K \\in \\mathbb{R}^{d \\times d} $\n",
    "\n",
    "- $ W_V \\in \\mathbb{R}^{d \\times d} $\n",
    "\n",
    "- $ Q \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ K \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ Q K^T \\in \\mathbb{R}^{n \\times n} $\n",
    "\n",
    "- $ V \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ A \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53c6a15-08eb-4674-9774-afb07fa1db05",
   "metadata": {},
   "source": [
    "### 3.2. Multi-Head Attention (MHA)\n",
    "\n",
    "Esta capa utiliza varias matrices de atención para capturar un número mayor de relaciones en paralelo entre los _tokens_.\n",
    "\n",
    "Cada una de estas matrices se llama _cabeza de atención_.\n",
    "\n",
    "Se definen $h$ cabezas de atención, cada una con sus correspondientes matrices de pesos para _queries_, _keys_, y _values_.\n",
    "\n",
    "Las dimensiones de las matrices de pesos de cada cabeza $i = 1, 2, \\ldots, h$ se reducen en función de las dimensiones de los _embeddings_. En el _paper_ original, con un tamaño de _embeddings_ de 512, se usan 8 cabezas de atención, reduciendo a 64 las dimensiones.\n",
    "\n",
    "- $ d_k = d_v = \\cfrac{d}{h} $\n",
    "\n",
    "- $ W_Q^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_K^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_V^i \\in \\mathbb{R}^{d \\times d_v} $\n",
    "\n",
    "La entrada $E^1$ a la capa se multiplica (proyecta) por cada matriz de pesos para obtener las correspondientes matrices de consultas, claves, y valores.\n",
    "\n",
    "- $ Q^i = E^1 W_Q^i $\n",
    "\n",
    "- $ K^i = E^1 W_K^i $\n",
    "\n",
    "- $ V^i = E^1 W_V^i $\n",
    "\n",
    "Se calcula la matriz de atención para cada cabeza.\n",
    "\n",
    "- $ A^i = \\operatorname{softmax} \\left( \\cfrac{Q^i (K^i)^T}{\\sqrt{d_k}} \\right) V^i = \\begin{bmatrix}\n",
    "a^i_{1,1} & a^i_{1,2} & \\ldots & a^i_{1,d_v}\n",
    "\\\\ a^i_{2,1} & a^i_{2,2} & \\ldots & a^i_{2,d_v}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ a^i_{n,1} & a^i_{n,2} & \\ldots & a^i_{n,d_v}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y todas las matrices de atención $A^i$ se concatenan en una sola.\n",
    "\n",
    "- $ A = \\operatorname{concat}\\left( A^1, A^2, ..., A^h \\right) = \\begin{bmatrix}\n",
    "a^1_{1,1} & a^1_{1,2} & \\ldots & a^1_{1,d_v} & a^2_{1,1} & a^2_{1,2} & \\ldots & a^2_{1,d_v} & \\ldots & a^h_{1,1} & a^h_{1,2} & \\ldots & a^h_{1,d_v}\n",
    "\\\\ a^1_{2,1} & a^1_{2,2} & \\ldots & a^1_{2,d_v} & a^2_{2,1} & a^2_{2,2} & \\ldots & a^2_{2,d_v} & \\ldots & a^h_{1,1} & a^h_{1,2} & \\ldots & a^h_{1,d_v}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ldots & \\vdots & \\ddots & \\vdots & \\ldots &\n",
    "\\\\ a^1_{n,1} & a^1_{n,2} & \\ldots & a^1_{n,d_v} & a^2_{n,1} & a^2_{n,2} & \\ldots & a^2_{n,d_v} & \\ldots & a^h_{n,1} & a^h_{n,2} & \\ldots & a^h_{n,d_v}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Conceptualmente, para una secuencia de entrada (frase) las cabezas de atención capturan relaciones surgidas durante el entrenamiento, como artículo-sustantivo, sujeto-verbo, verbo-adverbio, y así sucesivamente, pero también otras relaciones incluso más complejas, como por ejemplo relaciones espaciales entre los sujetos.\n",
    "\n",
    "Finalmente, se utiliza una nueva matriz de pesos $W^O$, inicializada y actualizada durante el entrenamiento, para devolver el resultado en las dimensiones originales.\n",
    "\n",
    "- $ W^O = \\begin{bmatrix}\n",
    "w^O_{1,1} & w^O_{1,2} & \\ldots & w^O_{1,d}\n",
    "\\\\ w^O_{2,1} & w^O_{2,2} & \\ldots & w^O_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w^O_{h d_v,1} & w^O_{h d_v,2} & \\ldots & w^O_{h d_v,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "La salida de la capa se obtiene multiplicando la matriz de atención por la matriz $W^O$.\n",
    "\n",
    "- $ E^2 = A W^O = \\begin{bmatrix}\n",
    "a^1_{1,1} & a^1_{1,2} & \\ldots & a^1_{1,d_v} & a^2_{1,1} & a^2_{1,2} & \\ldots & a^2_{1,d_v} & \\ldots & a^h_{1,1} & a^h_{1,2} & \\ldots & a^h_{1,d_v}\n",
    "\\\\ a^1_{2,1} & a^1_{2,2} & \\ldots & a^1_{2,d_v} & a^2_{2,1} & a^2_{2,2} & \\ldots & a^2_{2,d_v} & \\ldots & a^h_{1,1} & a^h_{1,2} & \\ldots & a^h_{1,d_v}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\ldots & \\vdots & \\ddots & \\vdots & \\ldots &\n",
    "\\\\ a^1_{n,1} & a^1_{n,2} & \\ldots & a^1_{n,d_v} & a^2_{n,1} & a^2_{n,2} & \\ldots & a^2_{n,d_v} & \\ldots & a^h_{n,1} & a^h_{n,2} & \\ldots & a^h_{n,d_v}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "w^O_{1,1} & w^O_{1,2} & \\ldots & w^O_{1,d}\n",
    "\\\\ w^O_{2,1} & w^O_{2,2} & \\ldots & w^O_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w^O_{h d_v,1} & w^O_{h d_v,2} & \\ldots & w^O_{h d_v,d}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Esta capa busca relaciones entre los _tokens_ de la secuencia de entrada, sin apoyarse en ninguna otra información, por lo que se conoce como _Self-Attention_.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E^1 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ W_Q^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_K^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_V^i \\in \\mathbb{R}^{d \\times d_v} $\n",
    "\n",
    "- $ Q^i \\in \\mathbb{R}^{n \\times d_k} $\n",
    "\n",
    "- $ K^i \\in \\mathbb{R}^{n \\times d_k} $\n",
    "\n",
    "- $ Q^i (K^i)^T \\in \\mathbb{R}^{n \\times n} $\n",
    "\n",
    "- $ V^i \\in \\mathbb{R}^{n \\times d_v} $\n",
    "\n",
    "- $ A^i \\in \\mathbb{R}^{n \\times d_v} $\n",
    "\n",
    "- $ A \\in \\mathbb{R}^{n \\times h d_v} $\n",
    "\n",
    "- $ W^O \\in \\mathbb{R}^{h d_v \\times d} $\n",
    "\n",
    "- $ E^2 \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd47205-1e19-48b9-a48e-c12179480566",
   "metadata": {},
   "source": [
    "### 3.3. Add\n",
    "\n",
    "En esta capa se suman la entrada y salida de la capa anterior.\n",
    "\n",
    "- $ E^3 = E^1 + E^2 $\n",
    "\n",
    "El proceso de añadir la entrada de una capa a su salida se conoce como _conexión residual_. Una técnica habitual para mejorar el rendimiento durante el entrenamiento de redes neuronales profundas.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E^1 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ E^2 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ E^3 \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8591e11d-fa07-44bb-b73a-9dc43d4746bc",
   "metadata": {},
   "source": [
    "### 3.4. Norm\n",
    "\n",
    "En esta capa se normaliza la salida de la capa anterior. Una técnica habitual que facilita un entrenamiento más rápido y estable.\n",
    "\n",
    "La capa aplica la función $\\operatorname{norm}$, fila a fila.\n",
    "\n",
    "- $ E^4 = \\operatorname{norm}\\left( E^3 \\right) $\n",
    "\n",
    "La función $\\text{norm}$ transforma la matriz dada para que todas sus filas tengan media $0$ y varianza $1$.\n",
    "\n",
    "- $ \\operatorname{norm}\\left( Z \\right) = \\gamma \\left( \\cfrac{Z - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\right) + \\beta$\n",
    "\n",
    "$\\mu$ (_mu_) es la media de $Z$.\n",
    "\n",
    "- $ \\mu = \\cfrac{1}{d} \\sum\\limits_{i=1}^{d} z_i $\n",
    "\n",
    "$\\sigma^2$ (_sigma_) es la varianza de $Z$.\n",
    "\n",
    "- $ \\sigma^2 = \\cfrac{1}{d} \\sum\\limits_{i=1}^{d} \\left( z_i - \\mu \\right)^2 $\n",
    "\n",
    "$\\gamma$ (_gamma_) y $\\beta$ (_beta_) son la escala y desplazamiento respectivamente, ambos parámetros inicializados y actualizados durante el entrenamiento.\n",
    "\n",
    "Y $\\epsilon$ (_epsilon_) es una constante de muy pequeña magnitud, utilizada para evitar divisiones por cero.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "- $ \\gamma = 1 $; $ \\beta = 0 $; $ \\epsilon = 0 $\n",
    "\n",
    "- $ \\mu \\left( [1, 2] \\right) = \\cfrac{1}{2} (1 + 2) = 1,5 $\n",
    "\n",
    "- $ \\sigma^2 \\left( [1, 2] \\right) = \\cfrac{1}{2} ((1 - 1,5)^2 + (2 - 1,5)^2) = 0,25 $\n",
    "\n",
    "- $ \\mu \\left( [4, 9] \\right) = \\cfrac{1}{2} (4 + 9) = 6,5 $\n",
    "\n",
    "- $ \\sigma^2 \\left( [4, 9] \\right) = \\cfrac{1}{2} ((4 - 6,5)^2 + (9 - 6,5)^2) = 6,25 $\n",
    "\n",
    "- $ \\operatorname{norm}\\left( \\begin{bmatrix}\n",
    "1 & 2\n",
    "\\\\ 4 & 9\n",
    "\\end{bmatrix} \\right) = \\begin{bmatrix}\n",
    "\\cfrac{1 - 1,5}{\\sqrt{0,25}} & \\cfrac{2 - 1,5}{\\sqrt{0,25}}\n",
    "\\\\ \\cfrac{4 - 6,5}{\\sqrt{6,25}} & \\cfrac{9 - 6,5}{\\sqrt{6,25}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "-1 & 1\n",
    "\\\\ -1 & 1\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E^3 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ Z \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ E^4 \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2996228-6dd8-455c-bd47-5c5f439a1e47",
   "metadata": {},
   "source": [
    "### 3.5. Feed Forward (FF)\n",
    "\n",
    "Esta capa añade principalmente no linealidad al encoder.\n",
    "\n",
    "Una red _feed forward_ es equivalente a aplicar una transformación afín, una función de activación no lineal, y otra transformación afín.\n",
    "\n",
    "- $ E^5 = \\operatorname{ReLU}\\left( E^4 W_1 + B_1 \\right) W_2 + B_2 $\n",
    "\n",
    "La primera transformación tiene el propósito de expandir las dimensiones de la matriz de entrada. Hasta cuatro veces su tamaño en el _paper_ original, por lo que dentro de esta capa las dimensiones se expanden desde 512 hasta 1048.\n",
    "\n",
    "- $ d_{ff} = 4 d $\n",
    "\n",
    "- $ W_1 \\in \\mathbb{R}^{d \\times d_{ff}} $\n",
    "\n",
    "Como función de activación se utiliza $\\text{ReLU}$, que se evalúa elemento a elemento, y retorna cero para los valores negativos y el propio valor para los positivos.\n",
    "\n",
    "- $ \\operatorname{ReLU}\\left(Z\\right) = \\operatorname{max}\\left(0, Z\\right) $\n",
    "\n",
    "La segunda transformación afín contrae las dimensiones del resultado al tamaño de entrada original.\n",
    "\n",
    "- $ W_2 \\in \\mathbb{R}^{d_{ff} \\times d} $\n",
    "\n",
    "A diferencia del mecanismo de atención, que busca relaciones entre _tokens_, esta capa se centra en aprender características de cada _token_ de manera individual.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E^4 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ W_1 \\in \\mathbb{R}^{d \\times d_{ff}} $\n",
    "\n",
    "- $ B_1 \\in \\mathbb{R}^{1 \\times d_{ff}} $\n",
    "\n",
    "- $ W_2 \\in \\mathbb{R}^{d_{ff} \\times d} $\n",
    "\n",
    "- $ B_2 \\in \\mathbb{R}^{1 \\times d} $\n",
    "\n",
    "- $ E^5 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "Las dimensiones de las matrices de sesgos resultan un tanto artificiosas, ya que es un mismo vector que se repite, mediante una técnica denominada _broadcasting_, para formar una matriz con las dimensiones adecuadas, algo que resulta necesario para que la expresión sea válida desde un punto de vista matemático.\n",
    "\n",
    "- $ X W + B = \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,d}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,d}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,d}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,m}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,m}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{d,1} & w_{d,2} & \\ldots & w_{d,m}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1 & b_2 & \\ldots & b_m\n",
    "\\\\ b_1 & b_2 & \\ldots & b_m\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ b_1 & b_2 & \\ldots & b_m\n",
    "\\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a564f73f-be63-4626-b4eb-9a26a0888b7f",
   "metadata": {},
   "source": [
    "### 3.6. Add\n",
    "\n",
    "Esta capa es una conexión residual entre la entrada y salida de la capa anterior.\n",
    "\n",
    "- $ E^6 = E^4 + E^5 $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E^4 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ E^5 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ E^6 \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3c4fe2-5572-4db5-9f54-cb5ad0d46117",
   "metadata": {},
   "source": [
    "### 3.7. Norm\n",
    "\n",
    "Esta capa normaliza la salida de la capa anterior.\n",
    "\n",
    "- $ E^7 = \\operatorname{norm}\\left( E^6 \\right) $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E^6 \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ E^7 \\in \\mathbb{R}^{n \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00fa584-c18e-4ee1-afd7-0bc7ee09f91a",
   "metadata": {},
   "source": [
    "## 4. Encoder Stack\n",
    "\n",
    "Un _transformer_ utiliza $N$ encoders en serie, 6 en el _paper_ original, conectando la salida de uno con la entrada del siguiente.\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> PE ─> Encoder 1 ─> Encoder 2 ─> ... ─> Encoder N ─> Decoder ─> Output\n",
    "```\n",
    "\n",
    "La salida de la pila de encoders es una representación de la secuencia de entrada, como un resumen del texto original.\n",
    "\n",
    "- $ E^7_N \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "Por convención, recibe el nombre de _contexto_ $C$.\n",
    "\n",
    "- $ C = E^7_N $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f99196-ff40-4298-b6aa-b0d57de0f9fd",
   "metadata": {},
   "source": [
    "## 5. Autoregression\n",
    "\n",
    "Un _transformer_ es un modelo autorregresivo, la salida del decoder alimenta su propia entrada.\n",
    "\n",
    "```\n",
    "Input ─> Embedding -> PE ─> Encoder x N ───────────────────┐\n",
    "                                                           ↓\n",
    "                              BOS ─> Embedding ─> PE ─> Decoder ─> Output\n",
    "                                  ↑                                  │\n",
    "                                  └──────────────────────────────────┘\n",
    "```\n",
    "\n",
    "El cálculo realizado por los encoders se realiza una única vez.\n",
    "\n",
    "El cálculo realizado por el decoder se realiza varias veces, iterando $t$ veces para generar un _token_ de cada vez."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cfa2f2-a010-4437-bc87-eb33caf6f0a1",
   "metadata": {},
   "source": [
    "### 5.1. Begin of Sentence (BOS)\n",
    "\n",
    "En la primera iteración, cuando aún no se ha generado ningún _token_, el decoder se alimenta con un _token_ especial denominado $\\text{BOS}$ (_Begin of Sentence_).\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ \\text{BOS} \\in \\mathbb{R} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b70823-3e0f-42f8-b540-74ce64090fb2",
   "metadata": {},
   "source": [
    "### 5.2. Embeddings\n",
    "\n",
    "Esta capa convierte los _tokens_ en sus correspondientes _embeddings_.\n",
    "\n",
    "El _token_ $\\text{BOS}$ tiene su correspondiente _embedding_ $E_{\\text{BOS}}$.\n",
    "\n",
    "- $ E_{\\text{BOS}} = W_E[BOS] \\begin{bmatrix}\n",
    "e_1 & e_2 & \\ldots & e_d\n",
    "\\end{bmatrix} $\n",
    "\n",
    "La matriz de pesos $W_E$ es compartida con la capa de _embeddings_ de entrada a los encoders.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ BOS \\in \\mathbb{R} $\n",
    "\n",
    "- $ W_E \\in \\mathbb{R}^{V \\times d} $\n",
    "\n",
    "- $ E_{\\text{BOS}} \\in \\mathbb{R}^{1 \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef86c11-bfe1-44a7-9403-f1555f1be7b9",
   "metadata": {},
   "source": [
    "### 5.3. Positional Encoding\n",
    "\n",
    "Los _embeddings_ se enriquecen mediante Positional Enconding antes de introducirlos en el decoder.\n",
    "\n",
    "Es necesario llevar la cuenta del número de _tokens_ generados hasta el momento por el decoder para sumar los valores correctos del Positional Enconding.\n",
    "\n",
    "En la primera iteración $t = 1$ el _token_ de entrada es $\\text{BOS}$, representado por el _embedding_ $E_{\\text{BOS}}$.\n",
    "\n",
    "- $ D^1_1 = E_{\\text{BOS}} + \\operatorname{PE}(0,j) = \\begin{bmatrix}\n",
    "e_1 & e_2 & \\ldots & e_d\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "\\operatorname{PE}(0, 0) & \\operatorname{PE}(0, 1) & \\ldots & \\operatorname{PE}(0, d-1)\n",
    "\\end{bmatrix}, \\quad \\text{para } j = 0, \\dots, d-1 $\n",
    "\n",
    "En el resto de iteraciones $t > 1$ el _token_ de entrada es el generado por el decoder en la iteración anterior $T_{t-1}$, representado por su correspondiente _embedding_ $E_{T_{t-1}}$.\n",
    "\n",
    "- $ D^1_t = E_{T_{t-1}} + \\operatorname{PE}(t-1,j) = \\begin{bmatrix}\n",
    "e_1 & e_2 & \\ldots & e_d\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "\\operatorname{PE}(t-1, 0) & \\operatorname{PE}(t-1, 1) & \\ldots & \\operatorname{PE}(t-1, d-1)\n",
    "\\end{bmatrix}, \\quad \\text{para } j = 0, \\dots, d-1 $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ E_{\\text{BOS}} \\in \\mathbb{R}^{1 \\times d} $\n",
    "\n",
    "- $ D^1_1 \\in \\mathbb{R}^{1 \\times d} $\n",
    "\n",
    "- $ E_{T_{t-1}} \\in \\mathbb{R}^{1 \\times d} $\n",
    "\n",
    "- $ D^1_t \\in \\mathbb{R}^{1 \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadd982c-ad52-42c1-a72e-288836187107",
   "metadata": {},
   "source": [
    "## 6. Decoder\n",
    "\n",
    "El decoder se compone de varias capas.\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> PE ─> Encoder x N ─────────┐\n",
    "                                                 ↓\n",
    "BOS ─> Embedding ─> PE ─> MHA ─> Add ─> Norm ─> MHA ─> Add ─> Norm ─> FF ─> Add ─> Norm ─> Output\n",
    "    ↑                  │          ↑          │          ↑          │         ↑               │\n",
    "    │                  └──────────┘          └──────────┘          └─────────┘               │\n",
    "    └────────────────────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "La salida de la pila de encoders no alimenta la entrada del decoder, sino que se inyecta en una capa intermedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9e5fe3-9ff0-4741-8d9d-091604c1ae0f",
   "metadata": {},
   "source": [
    "### 6.1. Masked Multi-Head Attention\n",
    "\n",
    "Esta capa es la que tiene en cuenta los _tokens_ generados hasta el momento por el decoder.\n",
    "\n",
    "Es necesario llevar la cuenta de la secuencia $Y$ de _embeddings_ generados hasta el momento para proyectar los valores correctos al calcular las matrices de atención.\n",
    "\n",
    "- $ Y \\in \\mathbb{R}^{t \\times d} $\n",
    "\n",
    "La capa calcula la atención con $h$ cabezas de atención.\n",
    "\n",
    "Cada cabeza $i = 1 \\ldots h$ tiene tres matrices de pesos $W_Q^i$, $W_K^i$, y $W_V^i$, inicializadas y actualizadas durante el entrenamiento.\n",
    "\n",
    "- $ d_k = d_v = d / h $\n",
    "\n",
    "- $ W_Q^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_K^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_V^i \\in \\mathbb{R}^{d \\times d_v} $\n",
    "\n",
    "Las matrices de _queries_, _keys_, y _values_ se calculan proyectando los _embeddings_ de los _tokens_ generados hasta el momento.\n",
    "\n",
    "- $ Q^i = Y W_Q^i $\n",
    "\n",
    "- $ K^i = Y W_K^i $\n",
    "\n",
    "- $ V^i = Y W_V^i $\n",
    "\n",
    "El primer paso para calcular la atención es calcular la matriz de _scores_.\n",
    "\n",
    "- $ \\cfrac{Q^i (K^i)^T}{\\sqrt{d_k}} $\n",
    "\n",
    "La matriz de _scores_ incrementa sus dimensiones en cada iteración.\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "s_{1,1}\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "s_{1,1} & s_{1,2}\n",
    "\\\\ s_{2,1} & s_{2,2}\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "s_{1,1} & s_{1,2} & s_{1,3}\n",
    "\\\\ s_{2,1} & s_{2,2} & s_{2,3}\n",
    "\\\\ s_{3,1} & s_{3,2} & s_{3,3}\n",
    "\\end{bmatrix}, \\ldots , \\begin{bmatrix}\n",
    "s_{1,1} & s_{1,2} & \\ldots & s_{1,t}\n",
    "\\\\ s_{2,1} & s_{2,2} & \\ldots & s_{2,t}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ s_{t,1} & s_{t,2} & \\ldots & s_{t,t}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "En la primera iteración la secuencia generada sólo tiene un _token_ que se presta atención a si mismo.\n",
    "\n",
    "En la segunda iteración la secuencia tiene dos _tokens_. La primera fila de la matriz de _scores_ representa la atención del primer _token_ consimo mismo y con el siguiente _token_ generado. Y la segunda fila la atención del segundo _token_ consigo mismo y con el primer _token_ generado.\n",
    "\n",
    "Pero esa matriz carece de sentido, ya que cuando se generó el primer token el segundo aún no existía y no pudo prestar atención al mismo.\n",
    "\n",
    "Para evitar tener en cuenta los _tokens_ que aún no se han generado, se aplica una función $\\operatorname{mask}$ que enmascara los elementos no deseados en la matriz.\n",
    "\n",
    "- $ \\operatorname{mask}\\left( \\cfrac{Q^i (K^i)^T}{\\sqrt{d_k}} \\right) $\n",
    "\n",
    "La función $\\operatorname{mask}$ sustituye los elementos no deseados de la matriz por $-\\infty$.\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "s_{1,1}\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "s_{1,1} & -\\infty\n",
    "\\\\ s_{2,1} & s_{2,2}\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "s_{1,1} & -\\infty & -\\infty\n",
    "\\\\ s_{2,1} & s_{2,2} & -\\infty\n",
    "\\\\ s_{3,1} & s_{3,2} & s_{3,3}\n",
    "\\end{bmatrix}, \\ldots , \\begin{bmatrix}\n",
    "s_{1,1} & -\\infty & \\ldots & -\\infty\n",
    "\\\\ s_{2,1} & s_{2,2} & \\ldots & -\\infty\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ s_{t,1} & s_{t,2} & \\ldots & s_{t,t}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "El siguiente paso es aplicar la función $\\operatorname{softmax}$ y proyectar los valores para calcular las matrices de atención.\n",
    "\n",
    "- $ A^i = \\operatorname{softmax} \\left( \\operatorname{mask} \\left( \\cfrac{Q^i (K^i)^T}{\\sqrt{d_k}} \\right) \\right) V^i $\n",
    "\n",
    "Recordando la forma de la función $\\operatorname{softmax}$, debe ser claro que sustituir los valores de los elementos de la matriz no deseados por $-\\infty$ tiene el efecto de que se ignoren, ya que $e^{-\\infty} = 0$.\n",
    "\n",
    "- $ \\operatorname{softmax} \\left( \\mathbf{z} \\right)_i = \\cfrac{e^{z_i}}{\\sum\\limits_{j=1}^{d} e^{z_j}} $\n",
    "\n",
    "Finalmente, se concatenan las matrices de atención y se multiplican por la matriz $W^O$, inicializada y actualizada durante el entrenamiento, para obtener la salida de la capa.\n",
    "\n",
    "- $ A = \\operatorname{concat}\\left( A^1, A^2, ..., A^h \\right) $\n",
    "\n",
    "- $ D^2_t = A W^O $\n",
    "\n",
    "Esta capa busca relaciones entre los _tokens_ de la secuencia de salida, sin apoyarse en ninguna otra información, por lo que se conoce como Self-Attention.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ D^1 \\in \\mathbb{R}^{t \\times d} $\n",
    "\n",
    "- $ W_Q^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_K^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_V^i \\in \\mathbb{R}^{d \\times d_v} $\n",
    "\n",
    "- $ Q^i \\in \\mathbb{R}^{t \\times d_k} $\n",
    "\n",
    "- $ K^i \\in \\mathbb{R}^{t \\times d_k} $\n",
    "\n",
    "- $ Q^i (K^i)^T \\in \\mathbb{R}^{t \\times t} $\n",
    "\n",
    "- $ V^i \\in \\mathbb{R}^{t \\times d_v} $\n",
    "\n",
    "- $ A^i \\in \\mathbb{R}^{t \\times d_v} $\n",
    "\n",
    "- $ A \\in \\mathbb{R}^{t \\times h d_v} $\n",
    "\n",
    "- $ W^O \\in \\mathbb{R}^{h d_v \\times d} $\n",
    "\n",
    "- $ D^2 \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a4676b-6c3f-43cf-b4e9-4629fd7f3a3b",
   "metadata": {},
   "source": [
    "### 6.2. Add\n",
    "\n",
    "Esta capa es una conexión residual entre la entrada y salida de la capa anterior.\n",
    "\n",
    "- $ D^3_t = D^1_t + D^2_t \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46785241-59ae-4cc4-9f8a-7d1149be8772",
   "metadata": {},
   "source": [
    "### 6.3. Norm\n",
    "\n",
    "Esta capa normaliza la salida de la capa anterior.\n",
    "\n",
    "- $ D^4_t = \\operatorname{norm}\\left( D^3_t \\right) \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f0971-45df-4a2b-83f7-83475537568f",
   "metadata": {},
   "source": [
    "### 6.4. Multi-Head Attention\n",
    "\n",
    "Esta capa es la que recibe el contexto calculado por la pila de encoders.\n",
    "\n",
    "La capa calcula la atención con $h$ cabezas de atención.\n",
    "\n",
    "Cada cabeza $i = 1 \\ldots h$ tiene tres matrices de pesos $W_Q^i$, $W_K^i$, y $W_V^i$, inicializadas y actualizadas durante el entrenamiento.\n",
    "\n",
    "- d_k = d_v = d / h\n",
    "\n",
    "Las matrices de _queries_ se calculan utilizando la salida $D^4_t$ de la capa anterior. \n",
    "\n",
    "- $ Q^i = D^4_t W_Q^i $\n",
    "\n",
    "La _query_ se realiza proyectando la salida de la capa anterior.\n",
    "\n",
    "Este cálculo es equivalente a preguntar cual es el siguiente _token_ (palabra) que tiene que generarse para la secuencia de salida.\n",
    "\n",
    "Por su parte, las matrices de _keys_ y _values_ se calculan con la salida $C$ de la pila de encoders.\n",
    "\n",
    "- $ K^i = C W_K^i $\n",
    "\n",
    "- $ V^i = C W_V^i $\n",
    "\n",
    "Las _keys_ y _values_ se calculan proyectando el contexto dado.\n",
    "\n",
    "Este cálculo es equivalente a buscar respuestas teniendo en cuenta el contexto resultante de analizar la secuencia de entrada (texto).\n",
    "\n",
    "La salida de la capa se obtiene calculando las matrices de atención, concatenando, y multiplicando por la matriz de pesos $W^O$, inicializada y actualizada durante el entrenamiento.\n",
    "\n",
    "- $ A^i = \\operatorname{softmax}\\left( \\cfrac{Q^i (K^i)^T}{\\sqrt{d_k}} \\right) V^i $\n",
    "\n",
    "- $ A = \\operatorname{concat}\\left( A^1, A^2, ..., A^h \\right) $\n",
    "\n",
    "- $ D^5_t = A W^O $\n",
    "\n",
    "Esta capa busca relaciones entre el contexto obtenido a partir de los _tokens_ de la secuencia de entrada, y los _tokens_ generados para la secuencia de salida, por lo que se conoce como _Cross-Attention_.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ D^4_t \\in \\mathbb{R}^{t \\times d} $\n",
    "\n",
    "- $ W_Q^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ Q^i \\in \\mathbb{R}^{t \\times d_k} $\n",
    "\n",
    "- $ C \\in \\mathbb{R}^{n \\times d} $\n",
    "\n",
    "- $ W_K^i \\in \\mathbb{R}^{d \\times d_k} $\n",
    "\n",
    "- $ W_V^i \\in \\mathbb{R}^{d \\times d_v} $\n",
    "\n",
    "- $ K^i \\in \\mathbb{R}^{n \\times d_k} $\n",
    "\n",
    "- $ Q^i (K^i)^T \\in \\mathbb{R}^{t \\times n} $\n",
    "\n",
    "- $ V^i \\in \\mathbb{R}^{n \\times d_v} $\n",
    "\n",
    "- $ A^i \\in \\mathbb{R}^{t \\times d_v} $\n",
    "\n",
    "- $ A \\in \\mathbb{R}^{t \\times h d_v} $\n",
    "\n",
    "- $ W^O \\in \\mathbb{R}^{h d_v \\times d} $\n",
    "\n",
    "- $ D^5_t \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750dc9b5-f7cf-40a4-9ccd-110124d90d1c",
   "metadata": {},
   "source": [
    "### 6.5. Add\n",
    "\n",
    "Esta capa es una conexión residual entre la entrada y salida de la capa anterior.\n",
    "\n",
    "- $ D^6_t = D^4_t + D^5_t \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dfdc35-cd1c-49d1-bdb2-50f41f582197",
   "metadata": {},
   "source": [
    "### 6.6. Norm\n",
    "\n",
    "Esta capa normaliza la salida de la capa anterior.\n",
    "\n",
    "- $ D^7_t = \\operatorname{norm}\\left( D^6_t \\right) \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965dba9-96b8-4814-ae95-7f800b246966",
   "metadata": {},
   "source": [
    "### 6.7. Feed Forward\n",
    "\n",
    "Esta capa añade principalmente no linealidad al decoder.\n",
    "\n",
    "- $ D^8_t = \\operatorname{ReLU}\\left( D^7_t W_1 + B_1 \\right) W_2 + B_2 $\n",
    "\n",
    "- $ d_{ff} = 4 d $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ D^7_t \\in \\mathbb{R}^{t \\times d} $\n",
    "\n",
    "- $ W_1 \\in \\mathbb{R}^{d \\times d_{ff}} $\n",
    "\n",
    "- $ B_1 \\in \\mathbb{R}^{1 \\times d_{ff}} $\n",
    "\n",
    "- $ W_2 \\in \\mathbb{R}^{d_{ff} \\times d} $\n",
    "\n",
    "- $ B_2 \\in \\mathbb{R}^{1 \\times d} $\n",
    "\n",
    "- $ D^8_t \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c720d7-1475-4d1c-9dd6-d2cc72815591",
   "metadata": {},
   "source": [
    "### 6.8. Add\n",
    "\n",
    "Esta capa es una conexión residual entre la entrada y salida de la capa anterior.\n",
    "\n",
    "- $ D^9_t = D^7_t + D^8_t \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00d491-7411-469d-b65d-0203a392fca2",
   "metadata": {},
   "source": [
    "### 6.9. Norm\n",
    "\n",
    "Esta capa normaliza la salida de la capa anterior.\n",
    "\n",
    "- $ D^{10}_t = \\operatorname{norm}\\left( D^9_t \\right) \\in \\mathbb{R}^{t \\times d} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b354cc31-7b10-48fe-9386-99c15c1fdd4c",
   "metadata": {},
   "source": [
    "## 7. Decoder Stack\n",
    "\n",
    "Un _transformer_ utiliza $M$ decoders en serie, 6 en el _paper_ original, conectando la salida de uno con la entrada del siguiente.\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> PE ─> Encoder x N ───────┬────────────┬─────────...───────┐\n",
    "                                               ↓            ↓                   ↓\n",
    "                  BOS ─> Embedding ─> PE ─> Decoder 1 ─> Decoder 2 ─> ... ─> Decoder M ─> Output\n",
    "                      ↑                                                                     │\n",
    "                      └─────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "El contexto calculado por los encoders es inyectado en la capa de atención correspondiente de cada decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a358cbe7-83ed-4815-8a74-7b85f8d4084b",
   "metadata": {},
   "source": [
    "## 8. Output\n",
    "\n",
    "El último paso del proceso consiste en generar un _token_ en cada iteración a partir de la salida de la pila de decoders.\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> PE ─> Encoder x N ─────────────────┐\n",
    "                                                         ↓\n",
    "                            BOS ─> Embedding ─> PE ─> Decoder x M ─> Lineal ─> SoftMax ─> Output\n",
    "                                ↑                                                           │\n",
    "                                └───────────────────────────────────────────────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432fd245-b899-44d1-9ba0-58da760e8be9",
   "metadata": {},
   "source": [
    "### 8.1. Lineal\n",
    "\n",
    "Esta capa realiza una transformación afín con dos matrices, $W_E$, y $B$.\n",
    "\n",
    "- $ O^1_t = D^{10}_t W_E^T + B $\n",
    "\n",
    "Proyecta las $d$ dimensiones de la salida de la pila de decoders hasta las $V$ dimensiones del vocabulario.\n",
    "\n",
    "La matriz $W_E$ es la misma compartida con todas las capas de _embeddings_ de la red. La matriz $B$ es inicializada y actualizada durante el entrenamiento.\n",
    "\n",
    "En el _paper_ original se utilizan vocabularios de más de 30.000 _tokens_, por lo que la matriz de entrada a la capa se expande desde sus 512 dimensiones originales hasta más de 30.000.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ D^{10}_t \\in \\mathbb{R}^{t \\times d} $\n",
    "\n",
    "- $ W_E^T \\in \\mathbb{R}^{d \\times V} $\n",
    "\n",
    "- $ B \\in \\mathbb{R}^{1 \\times V} $\n",
    "\n",
    "- $ O^1_t \\in \\mathbb{R}^{t \\times V} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cdd63b9-cdbd-4256-bab9-a6d1576593d3",
   "metadata": {},
   "source": [
    "### 8.2. SoftMax\n",
    "\n",
    "Esta capa aplica la función $\\operatorname{softmax}$ para calcular la distribución de probabilidad de la última fila de la salida de la capa anterior.\n",
    "\n",
    "- $ Z = \\operatorname{softmax}(O^1_t[t]) $\n",
    "\n",
    "Recordando que la salida de la función $\\operatorname{softmax}$ es un vector donde la suma de todos sus elementos es igual a $1$.\n",
    "\n",
    "La posición del elemento con el mayor valor de todos identifica el siguiente _token_ del vocabulario que con mayor probabilidad debería generarse.\n",
    "\n",
    "Para buscar dicho elemento se utiliza la función $\\operatorname{argmax}$, que encuentra el índice del elemento con el mayor valor de un vector.\n",
    "\n",
    "- $ i = \\operatorname{argmax}(Z) $\n",
    "\n",
    "Por ejemplo, si el mayor valor estuviera en la segunda columna entonces el _token_ a generar sería el segundo del vocabulario.\n",
    "\n",
    "$ \\begin{array}{c|l}\n",
    "\\text{Token} & \\text{Word}\n",
    "\\\\ \\hline 1 & \\text{casa}\n",
    "\\\\ \\bf{2} & \\textbf{árbol}\n",
    "\\\\ 3 & \\text{mesa}\n",
    "\\\\ \\vdots & \\vdots\n",
    "\\\\ V & \\text{perro}\n",
    "\\end{array} $\n",
    "\n",
    "Finalmente, la salida de la capa es el siguiente _token_ a generar en la secuencia de salida.\n",
    "\n",
    "- $ Y[t] = \\text{Vocabulary}[i] $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ O^1_t \\in \\mathbb{R}^{t \\times V} $\n",
    "\n",
    "- $ Z \\in \\mathbb{R}^{1 \\times V} $\n",
    "\n",
    "- $ i \\in \\mathbb{R} $\n",
    "\n",
    "- $ Y[t] \\in \\mathbb{R} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a78f86-e0f4-4542-a65d-4c12469aca08",
   "metadata": {},
   "source": [
    "## 9. End Of Sentence (EOS)\n",
    "\n",
    "El proceso se detiene cuando se genera un _token_ especial $\\text{EOS}$ (_End Of Sentence_), o cuando la longitud de la secuencia de salida alcanza un número máximo prefijado de _tokens_."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
