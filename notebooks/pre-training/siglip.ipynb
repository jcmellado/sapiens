{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02cb2dd2-8374-4fa5-bc20-14f428eb954e",
   "metadata": {},
   "source": [
    "# SigLIP\n",
    "\n",
    "Revisión informal de _SigLIP_ (_Sigmoid Loss for Language Image Pre-Training_).\n",
    "\n",
    "Modelo de código abierto publicado en marzo de 2023.\n",
    "\n",
    "- [https://arxiv.org/pdf/2303.15343](https://arxiv.org/pdf/2303.15343)\n",
    "\n",
    "Aunque los términos arquitectura y modelo se utilicen indistintamente, es habitual presentar _SigLIP_ como un método de _pre-entrenamiento_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0aa4c9-4b7b-4601-8b8e-8da185a284a8",
   "metadata": {},
   "source": [
    "## 1. Arquitectura\n",
    "\n",
    "_SigLIP_ es una variante de la arquitectura _CLIP_ (_Contrastive Language-Image Pre-Training_).\n",
    "\n",
    "- [https://github.com/jcmellado/sapiens/blob/main/notebooks/pre-training/clip.ipynb](https://github.com/jcmellado/sapiens/blob/main/notebooks/pre-training/clip.ipynb)\n",
    "\n",
    "Sigue la misma arquitectura, pero utiliza un mecanismo distinto para entrenar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033d8027-6c14-4f10-b510-39b23abbba88",
   "metadata": {},
   "source": [
    "### 1.1. Motivación\n",
    "\n",
    "_CLIP_ procesa _batches_ de $N$ imágenes y $N$ textos, donde la imagen en la posición $i$ se corresponde con el texto en la posición $i$.\n",
    "\n",
    "Para cada _batch_ genera puntuaciones con las que construye una matriz de $N \\times N$ dimensiones, buscando maximizar la puntuación de los elementos $(i, j)$ de la diagonal ($j = i$), y minimizar las puntuaciones del resto de elementos fuera de la diagonal ($j \\ne i$).\n",
    "\n",
    "Pero asume que para una imagen $i$, los textos en las posiciones $(i, j)$ con $j \\ne i$ no están relacionados de ninguna forma con la imagen $i$, y viceversa, lo cual no tiene por qué ser cierto.\n",
    "\n",
    "_SigLIP_ propone un método de entrenamiento alternativo para reducir el impacto de esta asunción, y optimizar además los cálculos a realizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7286366f-53f8-4ba1-a71d-7a26ce53abb8",
   "metadata": {},
   "source": [
    "## 2. Funciones de Pérdida\n",
    "\n",
    "El cambio propuesto por el modelo se fundamenta en el funcionamiento de distintas funciones de pérdidas, por lo que el análisis se enfoca desde esa perspectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24765d95-a684-4652-90df-3c6b05155873",
   "metadata": {},
   "source": [
    "### 2.1. Cross Entropy Loss\n",
    "\n",
    "_CLIP_ utiliza la función de pérdida de entropía cruzada (_Cross Entropy Loss_).\n",
    "\n",
    "Lo que puede expresarse utilizando la formulación del _paper_ original:\n",
    "\n",
    "- $ - \\dfrac{1}{2|\\mathcal{B}|} \\sum\\limits_{i=1}^{|\\mathcal{B}|} \\left( \\log \\overbrace{ \\dfrac{e^{t \\mathbf{x}_i \\cdot \\mathbf{y}_i}}{\\sum\\limits_{j=1}^{|\\mathcal{B}|} e^{t \\mathbf{x}_i \\cdot \\mathbf{y}_j}}}^{\\text{image vs text softmax}} + \\log \\overbrace{ \\dfrac{e^{t \\mathbf{x}_i \\cdot \\mathbf{y}_i}}{\\sum\\limits_{j=1}^{|\\mathcal{B}|} e^{t \\mathbf{x}_j \\cdot \\mathbf{y}_i}}}^{\\text{text vs image softmax}} \\right) $\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $\\mathbf{x}$ e $\\mathbf{y}$: los vectores de características normalizados, para imágenes y textos respectivamente, obtenidos por el modelo.\n",
    "\n",
    "- $t$ la: _temperatura_, un factor de escala calculado como $t = e^{t'}$, siendo $t'$ un parámetro global aprendido por el modelo.\n",
    "\n",
    "El modelo calcula la _similitud coseno_ como el producto escalar de los vectores de características normalizados $\\mathbf{x}$ e $\\mathbf{y}$, y la escala con la temperatura $t$.\n",
    "\n",
    "Aplica $softmax$ dos veces, una vez considerando la dimensión de las imágenes contra los textos, y otra vez considerando la dimensión de los textos contra las imágenes.\n",
    "\n",
    "- $ \\operatorname{softmax}(x_i)_j = \\dfrac{e^{x_{ij}}}{\\sum\\limits_{k=1}^{C} e^{x_{ik}}} $\n",
    "\n",
    "Calcula el logaritmo con signo negativo para penalizar los errores, a menor probabilidad, mayor error.\n",
    "\n",
    "Utiliza etiquetas implícitas, positivas de valor $1$ para los elementos sobre la diagonal, y $0$ para el resto.\n",
    "\n",
    "Y calcula la pérdida total como la media de los dos resultados obtenidos.\n",
    "\n",
    "_CLIP_ considera todas las puntuaciones a lo largo de cada dimensión para calcular las probabilidades, lo que implica calcular dos factores globales de normalización (los sumatorios de los divisores), lo que es computacionalmente ineficiente y aumenta las necesidades de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a35d58-491b-4eeb-a3ce-57e16b192915",
   "metadata": {},
   "source": [
    "### 2.2. Sigmoid Loss\n",
    "\n",
    "_SigLIP_ introduce el uso de la función de pérdida _Sigmoid Loss_ basada en la función sigmoide.\n",
    "\n",
    "Lo que puede expresarse utilizando la formulación del _paper_ original:\n",
    "\n",
    "- $ - \\dfrac{1}{|\\mathcal{B}|} \\sum\\limits_{i=1}^{|\\mathcal{B}|} \\sum\\limits_{j=1}^{|\\mathcal{B}|} \\underbrace{\\log \\dfrac{1}{1 + e^{z_{ij} (-t \\mathbf{x}_i \\cdot \\mathbf{y}_j  + b)}}}_{\\mathcal{L}_{ij}} $\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $\\mathbf{x}$ y $\\mathbf{y}$: los vectores de características normalizados, para imágenes y textos respectivamente, obtenidos por el modelo.\n",
    "\n",
    "- $z$: las etiquetas, con valor $1$ para las clases correctas, y valor $-1$ para las incorrectas.\n",
    "\n",
    "- $t$: la _temperatura_, un factor de escala calculado como $t = e^{t'}$, siendo $t'$ un parámetro global aprendido por el modelo, inicializado a $ln(10)$ en el _paper_.\n",
    "\n",
    "- $b$: un _bias_, un parámetro global aprendido por el modelo, añadido para evitar la proliferación de valores negativos al empezar el entrenamiento, inicializado a $-10$ en el _paper_.\n",
    "\n",
    "El modelo calcula la _similitud coseno_ como el producto escalar de los vectores de características normalizados $\\mathbf{x}$ e $\\mathbf{y}$, la escala con la temperatura $t$, y le suma el _bias_ $b$.\n",
    "\n",
    "Utiliza etiquetas $z_{ij}$ explícitas, positivas de valor $1$ para los elementos sobre la diagonal, y valor negativo de $-1$ para el resto.\n",
    "\n",
    "Aplica la función sigmoide a los valores calculados sobre la matriz de puntuaciones, elemento a elemento.\n",
    "\n",
    "- $ \\operatorname{sigmoid}(x_{ij}) = \\dfrac{1}{1 + e^{-x_{ij}}} $\n",
    "\n",
    "Calcula el logaritmo con signo negativo para penalizar los errores, a menor probabilidad, mayor error.\n",
    "\n",
    "Y calcula la pérdida total como la suma de los resultados individuales obtenidos normalizando por el tamaño del _batch_.\n",
    "\n",
    "_SigLIP_ considera sólo las puntuaciones individuales para calcular las probabilidades de cada clase, lo que evita el cálculo de los factores globales de normalización (los sumatorios de los divisores) presentes en el cálculo de la pérdida de _CLIP_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf3dbed-da67-4a9d-8751-6fa5808c3df9",
   "metadata": {},
   "source": [
    "### 2.3. Binary Cross Entropy\n",
    "\n",
    "_CLIP_ considera el entrenamiento una tarea de clasificación con múltiples clases.\n",
    "\n",
    "_SigLIP_ lo considera como una clasificación binaria.\n",
    "\n",
    "Para entender esto es necesario introducir la expresión general de la función de pérdida de la entropía cruzada binaria (_Binary Cross Entropy_).\n",
    "\n",
    "- $ - [z \\ln(p) + (1 - z) \\ln(1 - p)] $\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $z$ una etiqueta, con valor $1$ para la clase correcta, y $0$ para la incorrecta.\n",
    "\n",
    "- $p$ la probabilidad predicha por el modelo para la etiqueta $z = 1$.\n",
    "\n",
    "Para $z = 1$ la expresión general se simplifica para considerar sólo la probabilidad predicha por el modelo para la clase correcta.\n",
    "\n",
    "- $ - \\ln(p) $\n",
    "\n",
    "Y para $z = 0$ se simplifica al contrario de la probabilidad predicha para la clase correcta.\n",
    "\n",
    "- $ - \\ln(1 - p) $\n",
    "\n",
    "Por su parte, considerando la expresión general en _SigLIP_.\n",
    "\n",
    "- $ -\\ln(\\operatorname{sigmoid}(z y))$.\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $z$: una etiqueta, con valor $1$ para la clase correcta, y $-1$ para la incorrecta.\n",
    "\n",
    "- $y$: la puntuación bruta (_logit_) calculada por el modelo para la etiqueta $z$.\n",
    "\n",
    "La probabilidad calculada por el modelo es el resultado de aplicar la función sigmoide al _logit_.\n",
    "\n",
    "- $ p = \\operatorname{sigmoid}(y) $\n",
    "\n",
    "Para $z=1$ la expresión general se simplifica igual que en la función de pérdida de la entropía cruzada binaria.\n",
    "\n",
    "- $ - \\ln(\\operatorname{sigmoid}(y)) = - \\ln(p) $.\n",
    "\n",
    "Y para $z=-1$ se simplifica de igual forma, aunque requiere desarrollar la expresión para demostrarlo.\n",
    "\n",
    "- $ - \\ln(\\operatorname{sigmoid}(-y)) = - \\ln(1 - \\operatorname{sigmoid}(y)) = - \\ln(1 - p) $.\n",
    "\n",
    "Demostración:\n",
    "\n",
    "- $ \\operatorname{sigmoid}(-y) = \\dfrac{1}{1 + e^y} $\n",
    "\n",
    "- $ 1 - \\operatorname{sigmoid}(y) = 1 - \\dfrac{1}{1 + e^{-y}} = \\dfrac{1 + e^{-y} - 1}{1 + e^{-y}} = \\dfrac{e^{-y}}{1 + e^{-y}} \\dfrac{e^y}{e^y} = \\dfrac{1}{1 + e^y} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf99a05-26db-4bcf-9d1f-afabfa3393f9",
   "metadata": {},
   "source": [
    "## 3. Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568ac54-eb1e-47f0-a9bd-54cb80d728fb",
   "metadata": {},
   "source": [
    "### 3.1. Implementación\n",
    "\n",
    "En el _paper_ se proporciona el siguiente _pseudocódigo_:\n",
    "\n",
    "```python\n",
    "# img_emb : image model embedding [n, dim]\n",
    "# txt_emb : text model embedding [n, dim]\n",
    "# t_prime, b : learnable temperature and bias\n",
    "# n : mini-batch size\n",
    "\n",
    "t = exp(t_prime)\n",
    "zimg = l2_normalize(img_emb)\n",
    "ztxt = l2_normalize(txt_emb)\n",
    "\n",
    "logits = dot(zimg, ztxt.T) * t + b\n",
    "\n",
    "labels = 2 * eye(n) - ones(n) # -1 with diagonal 1\n",
    "\n",
    "l = -sum(log_sigmoid(labels * logits)) / n\n",
    "```\n",
    "\n",
    "Lo que corresponde a la siguiente secuencia de pasos:\n",
    "\n",
    "- Calcular la _temperatura_ y normalizar los _embeddings_.\n",
    "\n",
    "- Calcular los _logits_ como la _similitud coseno_, escalar por la _temperatura_, y sumar el _bias_.\n",
    "\n",
    "- Construir las etiquetas explícitas como una matriz con valores $1$ en su diagonal, y $-1$ fuera de ella.\n",
    "\n",
    "- Calcular la pérdida como la media de la función _log sigmoid_ aplicada al producto de las etiquetas por los _logits_.\n",
    "\n",
    "  - $ \\operatorname{log\\_sigmoid}(x) = \\ln(\\operatorname{sigmoid}(x)) = \\ln\\left(\\cfrac{1}{1 + e^{-x}}\\right) = - \\ln(1 + e^{-x}) $\n",
    "\n",
    "Algunas líneas relevantes del código fuente:\n",
    "\n",
    "```python\n",
    "logits = jnp.dot(zimg, ztxt.T)\n",
    "logits = logits * extras[\"t\"] + extras[\"b\"]\n",
    "\n",
    "eye = jnp.eye(zimg.shape[0])\n",
    "m1_diag1 = -jnp.ones_like(logits) + 2 * eye\n",
    "\n",
    "loglik = jax.nn.log_sigmoid(m1_diag1 * logits)\n",
    "nll = -jnp.sum(loglik, axis=-1)\n",
    "l = jnp.mean(nll)\n",
    "```\n",
    "\n",
    "Notar que parece haber cierta discrepancia en el signo al calcular los _logits_ con respecto a la fórmula del _paper_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae88124-9410-42c1-a4c7-cda73ae15b87",
   "metadata": {},
   "source": [
    "### 3.2. Optimización\n",
    "\n",
    "El _paper_ propone una técnica para calcular de forma eficiente la pérdida dividiendo el trabajo a realizar entre distintos dispositivos (_GPUs_ o _TPUs_).\n",
    "\n",
    "El _batch_ de $N$ imágenes y $N$ textos de entrada se divide en fragmentos (_chunks_), y cada fragmento se envía a un dispositivo distinto.\n",
    "\n",
    "Cada dispositivo calcula en paralelo y de forma independiente los vectores de características (_embeddings_) para las imágenes y textos de su fragmento, y la pérdida correspondiente.\n",
    "\n",
    "Al terminar el cálculo de los _embeddings_ y la pérdida local inicial, cada dispositivo intercambia sus _embeddings_ de texto con otro dispositivo. Los de imágenes permanecen en el dispositivo, no se intercambian.\n",
    "\n",
    "Cada dispositivo calcula entonces la pérdida con los nuevos _embeddings_ de texto recibidos, acumulando con la pérdida del paso anterior.\n",
    "\n",
    "El proceso se repite hasta que todos los dispositivos han procesado todos los _embeddings_ de texto.\n",
    "\n",
    "El resultado final se obtiene con una última operación que suma todas las pérdidas acumuladas en cada dispositivo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
