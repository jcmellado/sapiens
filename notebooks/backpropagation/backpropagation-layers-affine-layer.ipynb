{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10e2d9be-1221-4afe-9fcc-e86d0ca32403",
   "metadata": {},
   "source": [
    "# Backpropagation - Layers - AffineLayer\n",
    "\n",
    "Análisis y desarrollo de una capa de una red neuronal artificial que realiza una transformación afín."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9580dab8-bd4a-4509-b015-963469c00ce9",
   "metadata": {},
   "source": [
    "## 1. Transformación Afín\n",
    "\n",
    "La salida $Y$ de una capa que realiza una transformación afín es igual al producto de los pesos $W$ por las entradas $X$ más los sesgos $B$.\n",
    "\n",
    "- $ Y = WX + B $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbb8b04-cb82-4902-962f-7d4741379097",
   "metadata": {},
   "source": [
    "## 2. Parámetros\n",
    "\n",
    "Parámetros necesarios para crear la capa:\n",
    "\n",
    "- $ n $: Número de neuronas de entrada.\n",
    "\n",
    "- $ m $: Número de neuronas de salida.\n",
    "\n",
    "Parámetros inicializados y actualizados durante el entrenamiento:\n",
    "\n",
    "- $ W $: Pesos.\n",
    "\n",
    "- $ B $: Sesgos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f99196-ff40-4298-b6aa-b0d57de0f9fd",
   "metadata": {},
   "source": [
    "## 3. Forward Pass\n",
    "\n",
    "Valores de entrada:\n",
    "\n",
    "- $ X $: Entrada.\n",
    "\n",
    "Valores de salida:\n",
    "\n",
    "- $ Y $: Salida."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789d9aab-2315-4de4-bb98-20c90e5b884d",
   "metadata": {},
   "source": [
    "### 3.1. Salida\n",
    "\n",
    "Los valores de salida se obtienen multiplicando los pesos por la entrada y sumándole los sesgos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e5e805-3df9-47a4-9a79-6dfb425909ff",
   "metadata": {},
   "source": [
    "#### 3.1.1. Escalar\n",
    "\n",
    "El caso más sencillo ocurre cuando entrada, peso y sesgo son valores escalares.\n",
    "\n",
    "- $ y = wx + b$\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ w \\in \\mathbb{R} $\n",
    "\n",
    "- $ x \\in \\mathbb{R} $\n",
    "\n",
    "- $ b \\in \\mathbb{R} $\n",
    "\n",
    "- $ y \\in \\mathbb{R} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb64f4-8943-4c96-94d4-c6d728b3b60a",
   "metadata": {},
   "source": [
    "#### 3.1.2. Vectorial\n",
    "\n",
    "Cuando las entradas son vectores, se representan como vectores columna, con tantas filas como neuronas de entrada tiene la capa.\n",
    "\n",
    "- $ X = \\begin{bmatrix}\n",
    "x_{1}\n",
    "\\\\ x_{2}\n",
    "\\\\ \\vdots\n",
    "\\\\ x_{n}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y la salida es un vector columna, con tantas filas como neuronas de salida tiene la capa.\n",
    "\n",
    "- $ Y = W X + B = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1}\n",
    "\\\\ x_{2}\n",
    "\\\\ \\vdots\n",
    "\\\\ x_{n}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1\n",
    "\\\\ b_2\n",
    "\\\\ \\vdots\n",
    "\\\\ b_m\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "y_{1}\n",
    "\\\\ y_{2}\n",
    "\\\\ \\vdots\n",
    "\\\\ y_{m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ W \\in \\mathbb{R}^{m \\times n} $\n",
    "\n",
    "- $ X \\in \\mathbb{R}^{n \\times 1} $\n",
    "\n",
    "- $ B \\in \\mathbb{R}^{m \\times 1} $\n",
    "\n",
    "- $ Y \\in \\mathbb{R}^{m \\times 1} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a39cc3f-f5db-491c-9862-cde7f04c8b39",
   "metadata": {},
   "source": [
    "#### 3.1.3. Matricial\n",
    "\n",
    "Cuando se procesan _batches_, o _mini-batches_, la entrada es una matriz con $N$ entradas que se evaluan simultáneamente. En esta matriz, cada columna representa una entrada diferente.\n",
    "\n",
    "- $X = \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,N}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,N}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y cada columna en la matriz de salida corresponde al resultado de evaluar la columna correspondiente en la matriz de entrada.\n",
    "\n",
    "- $ Y = W X + B = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,N}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,N}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1 & b_1 & \\ldots & b_1\n",
    "\\\\ b_2 & b_2 & \\ldots & b_2\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ b_m & b_m & \\ldots & b_m\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "y_{1,1} & y_{1,2} & \\ldots & y_{1,N}\n",
    "\\\\ y_{2,1} & y_{2,2} & \\ldots & y_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ y_{m,1} & y_{m,2} & \\ldots & y_{m,N}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "La matriz de sesgos resulta un tanto artificial, ya que en cada columna se repite el mismo vector de sesgos una y otra vez. Pero es algo que resulta necesario para que la expresión sea correcta desde un punto de vista matemático.\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ W \\in \\mathbb{R}^{m \\times n} $\n",
    "\n",
    "- $ X \\in \\mathbb{R}^{n \\times N} $\n",
    "\n",
    "- $ B \\in \\mathbb{R}^{m \\times N} $\n",
    "\n",
    "- $ Y \\in \\mathbb{R}^{m \\times N} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6669ee19-c5c6-4694-9961-787539836b5b",
   "metadata": {},
   "source": [
    "## 4. Backward Pass\n",
    "\n",
    "Valores de entrada:\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial Y} $: Derivada parcial de la pérdida respecto a la salida de la capa.\n",
    "\n",
    "Valores de salida:\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial X} $: Derivada parcial de la pérdida respecto a la entrada de la capa.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial W} $: Derivada parcial de la pérdida respecto a los pesos de la capa.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial B} $: Derivada parcial de la pérdida respecto a los sesgos de la capa.\n",
    "\n",
    "Siempre teniendo en cuenta que al trabajar con vectores y matrices se utilizan gradientes en vez de derivadas.\n",
    "\n",
    "- $ \\nabla_X{L} $: Gradiente de la pérdida respecto a la entrada de la capa.\n",
    "\n",
    "- $ \\nabla_W{L} $: Gradiente de la pérdida respecto a los pesos de la capa.\n",
    "\n",
    "- $ \\nabla_B{L} $: Gradiente de la pérdida respecto a los sesgos de la capa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc99f7c5-9f0e-4a7e-8e5c-636e74438592",
   "metadata": {},
   "source": [
    "### 4.1. Gradiente de la Pérdida Respecto a la Entrada\n",
    "\n",
    "El primer resultado a calcular por el _backward pass_ es la derivada parcial de la pérdida respecto a la entrada de la capa.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial X} $\n",
    "\n",
    "Derivada que puede calcularse aplicando la regla de la cadena.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial X} = \\cfrac{\\partial L}{\\partial Y} \\cfrac{\\partial Y}{\\partial X} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddc70a2-2f87-4286-9586-ac5c9d95a561",
   "metadata": {},
   "source": [
    "#### 4.1.1. Escalar\n",
    "\n",
    "El caso más sencillo ocurre cuando entrada, peso y sesgo son valores escalares.\n",
    "\n",
    "- $ y = wx + b$\n",
    "\n",
    "En este caso debe ser claro que la derivada parcial de la salida $y$ respecto a la entrada $x$ es igual al peso $w$. Es decir, cuando se incrementa la entrada en una unidad se incrementa la salida de manera proporcional al peso por el que se encuentra multiplicada la entrada.\n",
    "\n",
    "- $ \\cfrac{\\partial y}{\\partial x} = w $\n",
    "\n",
    "Sustituyendo en la regla de la cadena se encuentra la derivada parcial buscada.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x} = \\cfrac{\\partial L}{\\partial y} \\cfrac{\\partial y}{\\partial x} = \\cfrac{\\partial L}{\\partial y} w $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ w \\in \\mathbb{R} $\n",
    "\n",
    "- $ x \\in \\mathbb{R} $\n",
    "\n",
    "- $ b \\in \\mathbb{R} $\n",
    "\n",
    "- $ y \\in \\mathbb{R} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a90a9f-9ecc-44ec-8cba-ac694481e020",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4.1.2. Vectorial\n",
    "\n",
    "Cuando la entrada es un vector, el gradiente de la pérdida respecto a la salida (valor de entrada) es un vector.\n",
    "\n",
    "- $ \\nabla_Y{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el gradiente de la pérdida respecto a la entrada (valor a calcular) es también un vector.\n",
    "\n",
    "- $ \\nabla_X{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial x_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial x_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial x_n}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Donde cada elemento del vector puede calcularse de manera individual utilizando la regla de la cadena para varias variables.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_i} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_p} \\cfrac{\\partial y_p}{\\partial x_i} \\quad \\bf{(1)} $\n",
    "\n",
    "Recordando cómo se calcula la salida cuando las entradas son vectores.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "y_1\n",
    "\\\\ y_2\n",
    "\\\\ \\vdots\n",
    "\\\\ y_m\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1}\n",
    "\\\\ x_{2}\n",
    "\\\\ \\vdots\n",
    "\\\\ x_{n}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1\n",
    "\\\\ b_2\n",
    "\\\\ \\vdots\n",
    "\\\\ b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y desarrollando cada elemento, puede entenderse como afecta cada entrada en el cálculo de cada salida.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "w_{1,1} x_1 + w_{1,2} x_2 + \\ldots + w_{1,n} x_n + b_1\n",
    "\\\\ w_{2,1} x_1 + w_{2,2} x_2 + \\ldots + w_{2,n} x_n + b_2\n",
    "\\\\ \\vdots\n",
    "\\\\ w_{m,1} x_1 + w_{m,2} x_2 + \\ldots + w_{m,n} x_n + b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Debe ser claro que cuando se incrementa una entrada en una unidad se incrementan las salidas de manera proporcional al peso por el que se encuentra multiplicada dicha entrada. Es decir, que la derivada parcial de una salida con respecto a una entrada es igual al peso por el que se encuentra multiplicada dicha entrada. De forma que puede calcularse una derivada parcial por cada una de las $m$ salidas con respecto a cada una de las $n$ entradas. Derivadas parciales que pueden reunirse en una matriz, llamada matriz jacobiana.\n",
    "\n",
    "- $ \\cfrac{\\partial Y}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_1}{\\partial x_1} & \\cfrac{\\partial y_1}{\\partial x_2} & \\ldots & \\cfrac{\\partial y_1}{\\partial x_n}\n",
    "\\\\ \\cfrac{\\partial y_2}{\\partial x_1} & \\cfrac{\\partial y_2}{\\partial x_2} & \\ldots & \\cfrac{\\partial y_2}{\\partial x_n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_m}{\\partial x_1} & \\cfrac{\\partial y_m}{\\partial x_2} & \\ldots & \\cfrac{\\partial y_m}{\\partial x_n}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} = W $\n",
    "\n",
    "Analizando los valores de la matriz, se observa un patrón donde el primer subíndice de los pesos coincide con el subíndice de la salida ($p$), y el segundo subíndice de los pesos coincide con el subíndice de la entrada ($i$).\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{\\color{red}{1}}}{\\partial x_{\\color{blue}{1}}} & \\cfrac{\\partial y_{\\color{red}{1}}}{\\partial x_{\\color{blue}{2}}} & \\ldots & \\cfrac{\\partial y_{\\color{red}{1}}}{\\partial x_{\\color{blue}{n}}}\n",
    "\\\\ \\cfrac{\\partial y_{\\color{red}{2}}}{\\partial x_{\\color{blue}{1}}} & \\cfrac{\\partial y_{\\color{red}{2}}}{\\partial x_{\\color{blue}{2}}} & \\ldots & \\cfrac{\\partial y_{\\color{red}{2}}}{\\partial x_{\\color{blue}{n}}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{\\color{red}{m}}}{\\partial x_{\\color{blue}{1}}} & \\cfrac{\\partial y_{\\color{red}{m}}}{\\partial x_{\\color{blue}{2}}} & \\ldots & \\cfrac{\\partial y_{\\color{red}{m}}}{\\partial x_{\\color{blue}{n}}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{{\\color{red}{1}},{\\color{blue}{1}}} & w_{{\\color{red}{1}},{\\color{blue}{2}}} & \\ldots & w_{{\\color{red}{1}},{\\color{blue}{n}}}\n",
    "\\\\ w_{{\\color{red}{2}},{\\color{blue}{1}}} & w_{{\\color{red}{2}},{\\color{blue}{2}}} & \\ldots & w_{{\\color{red}{2}},{\\color{blue}{n}}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{{\\color{red}{m}},{\\color{blue}{1}}} & w_{{\\color{red}{m}},{\\color{blue}{2}}} & \\ldots & w_{{\\color{red}{m}},{\\color{blue}{n}}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Es decir, una salida $y_p$ se ve afectada por una entrada $x_i$ en una cuantía igual al valor del peso $w_{p,i}$ por el que se encuentra multiplicada.\n",
    "\n",
    "- $ \\cfrac{\\partial y_p}{\\partial x_i} = w_{p,i} $\n",
    "\n",
    "Sustituyendo en la expresión de cálculo de los elementos del gradiente buscado $\\bf{(1)}$.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_i} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_p} \\cfrac{\\partial y_p}{\\partial x_i} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_p} w_{p,i} = \\cfrac{\\partial L}{\\partial y_1} w_{1,i} + \\cfrac{\\partial L}{\\partial y_2} w_{2,i} + \\ldots + \\cfrac{\\partial L}{\\partial y_m} w_{m,i} $\n",
    "\n",
    "Se pueden desarrollar todos sus elementos.\n",
    "\n",
    "- $ \\nabla_X{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial x_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial x_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial x_n}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1} w_{1,1} + \\cfrac{\\partial L}{\\partial y_2} w_{2,1} + \\ldots + \\cfrac{\\partial L}{\\partial y_m} w_{m,1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_1} w_{1,2} + \\cfrac{\\partial L}{\\partial y_2} w_{2,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_m} w_{m,2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_1} w_{1,n} + \\cfrac{\\partial L}{\\partial y_2} w_{2,n} + \\ldots + \\cfrac{\\partial L}{\\partial y_m} w_{m,n}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y simplificar atendiendo a la forma de los sumandos.\n",
    "\n",
    "- $ \\nabla_X{L} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{2,1} & \\ldots & w_{m,1}\n",
    "\\\\ w_{1,2} & w_{2,2} & \\ldots & w_{m,2}\n",
    "\\\\ \\vdots\n",
    "\\\\ w_{1,n} & w_{2,n} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_m}\n",
    "\\end{bmatrix} = W^T \\nabla_Y{L} $\n",
    "\n",
    "De forma que el gradiente de la pérdida respecto a la entrada de la capa $\\nabla_X{L}$ se puede calcular como el producto de la traspuesta de la matriz de pesos de la capa $W^T$ por el gradiente de la pérdida respecto a la salida de la capa $\\nabla_Y{L}$.\n",
    "\n",
    "- $ \\nabla_X{L} = W^T \\nabla_Y{L} $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ W^T \\in \\mathbb{R}^{n \\times m} $\n",
    "\n",
    "- $ \\nabla_Y{L} \\in \\mathbb{R}^{m \\times 1} $\n",
    "\n",
    "- $ \\nabla_X{L} \\in \\mathbb{R}^{n \\times 1} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63583482-1f36-4058-8d80-5fea2c54703a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 4.1.3. Matricial\n",
    "\n",
    "Cuando se evalúa un _batch_ de $N$ entradas, el gradiente de la pérdida respecto a la salida (valor de entrada) es una matriz.\n",
    "\n",
    "- $ \\nabla_Y{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} & \\cfrac{\\partial L}{\\partial y_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} & \\cfrac{\\partial L}{\\partial y_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} & \\cfrac{\\partial L}{\\partial y_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{m,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el gradiente de la pérdida respecto a la entrada (valor a calcular) es también una matriz.\n",
    "\n",
    "- $ \\nabla_X{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial x_{1,1}} & \\cfrac{\\partial L}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial x_{2,1}} & \\cfrac{\\partial L}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial x_{n,1}} & \\cfrac{\\partial L}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial L}{\\partial x_{n,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Donde cada elemento de la matriz puede calcularse de manera individual utilizando la regla de la cadena para varias variables.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial x_{i,j}} \\quad \\bf(1) $\n",
    "\n",
    "Recordando como se calcula la salida cuando la entrada es un _batch_ de vectores.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "y_{1,1} & y_{1,2} & \\ldots & y_{1,N}\n",
    "\\\\ y_{2,1} & y_{2,2} & \\ldots & y_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ y_{m,1} & y_{m,2} & \\ldots & y_{m,N}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,N}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,N}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1 & b_1 & \\ldots & b_1\n",
    "\\\\ b_2 & b_2 & \\ldots & b_2\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ b_m & b_m & \\ldots & b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y desarrollando cada elemento, puede entenderse como afecta cada entrada en el cálculo de cada salida.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "w_{1,1} x_{1,1} + w_{1,2} x_{2,1} + \\ldots + w_{1,n} x_{n,1} + b_1 & w_{1,1} x_{1,2} + w_{1,2} x_{2,2} + \\ldots + w_{1,n} x_{n,2} + b_1 & \\ldots & w_{1,1} x_{1,N} + w_{1,2} x_{2,N} + \\ldots + w_{1,n} x_{n,N} + b_1\n",
    "\\\\ w_{2,1} x_{1,1} + w_{2,2} x_{2,1} + \\ldots + w_{2,n} x_{n,1} + b_2 & w_{2,1} x_{1,2} + w_{2,2} x_{2,2} + \\ldots + w_{2,n} x_{n,2} + b_2 & \\ldots & w_{2,1} x_{1,N} + w_{2,2} x_{2,N} + \\ldots + w_{2,n} x_{n,N} + b_2\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} x_{1,1} + w_{m,2} x_{2,1} + \\ldots + w_{m,n} x_{n,1} + b_m & w_{m,1} x_{1,2} + w_{m,2} x_{2,2} + \\ldots + w_{m,n} x_{n,2} + b_m & \\ldots & w_{m,1} x_{1,N} + w_{m,2} x_{2,N} + \\ldots + w_{m,n} x_{n,N} + b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Debe ser claro que cuando se incrementa una entrada en una unidad se incrementan las salidas de manera proporcional al peso por el que se encuentra multiplicada dicha entrada. Es decir, que la derivada parcial de una salida con respecto a una entrada es igual al peso por el que se encuentra multiplicada dicha entrada. No obstante, calcular todas las derivadas parciales requiere construir un tensor para cada una de las $m \\times N$ salidas con respecto a cada una de las $n \\times N$ entradas, lo que puede ser computacionalmente ineficiente.\n",
    "\n",
    "- $ \\cfrac{\\partial Y}{\\partial X} \\in \\mathbb{R}^{m \\times N \\times n \\times N} $\n",
    "\n",
    "Abusando quizás un poco de la notación, se pueden examinar algunas de estas derivadas parciales.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{1,1}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,1}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{1,2}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,2}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{1,2}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,2}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{1,2}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{1,2}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,2}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,2}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{1,2}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{1,2}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{1,N}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,N}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{1,N}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,N}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{1,N}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{1,N}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,N}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,N}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{1,N}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{1,N}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{2,1}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,1}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{2,1}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{2,1}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{2,1}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{2,1}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{2,1}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,1}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{2,1}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{2,1}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{2,2}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,2}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{2,2}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{2,2}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{2,2}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{2,2}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{2,2}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,2}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{2,2}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{2,2}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{2,N}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,N}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{2,N}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{2,N}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{2,N}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{2,N}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{2,N}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,N}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{2,N}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{2,N}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{m,1}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,1}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{m,1}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{m,1}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{m,1}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{m,1}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{m,1}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,1}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{m,1}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{m,1}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix} \n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{m,2}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,2}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{m,2}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{m,2}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{m,2}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{m,2}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{m,2}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,2}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{m,2}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{m,2}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{m,N}}{\\partial X} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,N}}{\\partial x_{1,1}} & \\cfrac{\\partial y_{m,N}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{m,N}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{m,N}}{\\partial x_{2,1}} & \\cfrac{\\partial y_{m,N}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{m,N}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,N}}{\\partial x_{n,1}} & \\cfrac{\\partial y_{m,N}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{m,N}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Desarrollando los elementos, se observan dos patrones.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{1,1}}{\\partial X} = \\begin{bmatrix}\n",
    "w_{1,1} & 0 & \\ldots & 0\n",
    "\\\\ w_{1,2} & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{1,n} & 0 & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{1,2}}{\\partial X} = \\begin{bmatrix}\n",
    "0 & w_{1,1} & \\ldots & 0\n",
    "\\\\ 0 & w_{1,2} & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & w_{1,n} & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{1,N}}{\\partial X} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & w_{1,1}\n",
    "\\\\ 0 & 0 & \\ldots & w_{1,2}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & w_{1,n}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{2,1}}{\\partial X} = \\begin{bmatrix}\n",
    "w_{2,1} & 0 & \\ldots & 0\n",
    "\\\\ w_{2,2} & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{2,n} & 0 & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{2,2}}{\\partial X} = \\begin{bmatrix}\n",
    "0 & w_{2,1} & \\ldots & 0\n",
    "\\\\ 0 & w_{2,2} & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & w_{2,n} & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{2,N}}{\\partial X} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & w_{2,1}\n",
    "\\\\ 0 & 0 & \\ldots & w_{2,2}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & w_{2,n}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{m,1}}{\\partial X} = \\begin{bmatrix}\n",
    "w_{m,1} & 0 & \\ldots & 0\n",
    "\\\\ w_{m,2} & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,n} & 0 & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{m,2}}{\\partial X} = \\begin{bmatrix}\n",
    "0 & w_{m,1} & \\ldots & 0\n",
    "\\\\ 0 & w_{m,2} & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & w_{m,n} & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{m,N}}{\\partial X} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & w_{m,1}\n",
    "\\\\ 0 & 0 & \\ldots & w_{m,2}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "El primer patrón se observa columna a columna, donde los únicos elementos distintos de cero se encuentran en las columnas donde el segundo subíndice de las salidas ($q$) coincide con el segundo subíndice de las entradas ($j$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,{\\color{magenta}{1}}}}{\\partial x_{1,{\\color{magenta}{1}}}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{1,{\\color{magenta}{1}}}}{\\partial x_{2,{\\color{magenta}{1}}}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,{\\color{magenta}{1}}}}{\\partial x_{n,{\\color{magenta}{1}}}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\color{magenta}{w_{1,1}} & 0 & \\ldots & 0\n",
    "\\\\ \\color{magenta}{w_{1,2}} & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\color{magenta}{w_{1,n}} & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el segundo patrón se observa en las columnas con valores distintos de cero, donde el primer subíndice de los pesos coincide con el primer subíndice de la salida ($p$), y el segundo subíndice de los pesos coincide con el primer subíndice de la entrada ($i$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{{\\color{red}{1}},1}}{\\partial x_{{\\color{blue}{1}},1}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{1,N}}\n",
    "\\\\ \\cfrac{\\partial y_{{\\color{red}{1}},1}}{\\partial x_{{\\color{blue}{2}},1}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{{\\color{red}{1}},1}}{\\partial x_{{\\color{blue}{n}},1}} & \\cfrac{\\partial y_{1,1}}{\\partial x_{n,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial x_{n,N}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{{\\color{red}{1}},{\\color{blue}{1}}} & 0 & \\ldots & 0\n",
    "\\\\ w_{{\\color{red}{1}},{\\color{blue}{2}}} & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{{\\color{red}{1}},{\\color{blue}{n}}} & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Es decir, una salida $y_{p,q}$ se ve afectada por una entrada $x_{i,j}$ en una cuantía igual al valor del peso $w_{p,i}$ por el que se encuentra multiplicada.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{p,q}}{\\partial x_{i,j}} = \\begin{cases} w_{p,i} & \\text{si } q = j \\\\ 0 & \\text{en caso contrario} \\end{cases} $\n",
    "\n",
    "Sustituyendo en la expresión de cálculo de los elementos del gradiente buscado $\\bf(1)$.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial x_{i,j}} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\left( \\cfrac{\\partial L}{\\partial y_{p,1}} \\cfrac{\\partial y_{p,1}}{\\partial x_{i,j}} + \\cfrac{\\partial L}{\\partial y_{p,2}} \\cfrac{\\partial y_{p,2}}{\\partial x_{i,j}} + \\ldots + \\cfrac{\\partial L}{\\partial y_{p,j}} \\cfrac{\\partial y_{p,j}}{\\partial x_{i,j}} + \\ldots + \\cfrac{\\partial L}{\\partial y_{p,N}} \\cfrac{\\partial y_{p,N}}{\\partial x_{i,j}} \\right) $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\left( \\cfrac{\\partial L}{\\partial y_{p,1}} 0 + \\cfrac{\\partial L}{\\partial y_{p,2}} 0 + \\ldots + \\cfrac{\\partial L}{\\partial y_{p,j}} w_{p,i} + \\ldots + \\cfrac{\\partial L}{\\partial y_{p,N}} 0 \\right) $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_{p,j}} w_{p,i} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial x_{i,j}} = \\cfrac{\\partial L}{\\partial y_{1,j}} w_{1,i} + \\cfrac{\\partial L}{\\partial y_{2,j}} w_{2,i} +\n",
    "\\ldots + \\cfrac{\\partial L}{\\partial y_{m,j}} w_{m,i} $\n",
    "\n",
    "Se pueden desarrollar todos los elementos del gradiente evitando el cálculo de los valores que son igual a cero y no aportan nada al resultado.\n",
    "\n",
    "- $ \\nabla_X{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} w_{1,1} + \\cfrac{\\partial L}{\\partial y_{2,1}} w_{2,1} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,1}} w_{m,1}\n",
    "& \\cfrac{\\partial L}{\\partial y_{1,2}} w_{1,1} + \\cfrac{\\partial L}{\\partial y_{2,2}} w_{2,1} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,2}} w_{m,1}\n",
    "& \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}} w_{1,1} + \\cfrac{\\partial L}{\\partial y_{2,N}} w_{2,1} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,N}} w_{m,1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{1,1}} w_{1,2} + \\cfrac{\\partial L}{\\partial y_{2,1}} w_{2,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,1}} w_{m,2}\n",
    "& \\cfrac{\\partial L}{\\partial y_{1,2}} w_{1,2} + \\cfrac{\\partial L}{\\partial y_{2,2}} w_{2,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,2}} w_{m,2}\n",
    "& \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}} w_{1,2} + \\cfrac{\\partial L}{\\partial y_{2,N}} w_{2,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,N}} w_{m,2}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{1,1}} w_{1,n} + \\cfrac{\\partial L}{\\partial y_{2,1}} w_{2,n} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,1}} w_{m,n}\n",
    "& \\cfrac{\\partial L}{\\partial y_{1,2}} w_{1,n} + \\cfrac{\\partial L}{\\partial y_{2,2}} w_{2,n} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,2}} w_{m,n}\n",
    "& \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}} w_{1,n} + \\cfrac{\\partial L}{\\partial y_{2,N}} w_{2,n} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,N}} w_{m,n}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Expresión que puede simplificarse atendiendo a la forma de los sumandos.\n",
    "\n",
    "- $ \\nabla_X{L} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{2,1} & \\ldots & w_{m,1}\n",
    "\\\\ w_{1,2} & w_{2,2} & \\ldots & w_{m,2}\n",
    "\\\\ \\vdots\n",
    "\\\\ w_{1,n} & w_{2,n} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} & \\cfrac{\\partial L}{\\partial y_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} & \\cfrac{\\partial L}{\\partial y_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} & \\cfrac{\\partial L}{\\partial y_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{m,N}}\n",
    "\\end{bmatrix} = W^T \\nabla_Y{L} $\n",
    "\n",
    "De forma que el gradiente de la pérdida respecto a la entrada de la capa $\\nabla_X{L}$ se puede calcular como el producto de la traspuesta de la matriz de pesos de la capa $W^T$ por el gradiente de la pérdida respecto a la salida de la capa $\\nabla_Y{L}$.\n",
    "\n",
    "- $ \\nabla_X{L} = W^T \\nabla_Y{L} $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ W^T \\in \\mathbb{R}^{n \\times m} $\n",
    "\n",
    "- $ \\nabla_Y{L} \\in \\mathbb{R}^{m \\times N} $\n",
    "\n",
    "- $ \\nabla_X{L} \\in \\mathbb{R}^{n \\times N} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7e894d-494c-415a-bd18-d4d6976671c9",
   "metadata": {},
   "source": [
    "### 4.2. Gradiente de la Pérdida Respecto a los Pesos\n",
    "\n",
    "El segundo resultado a calcular por el _backward pass_ es la derivada de la pérdida respecto a los pesos de la capa.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial W} $\n",
    "\n",
    "La derivada a calcular puede encontrarse aplicando la regla de la cadena.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial W} = \\cfrac{\\partial L}{\\partial Y} \\cfrac{\\partial Y}{\\partial W} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8a24c-2199-48cd-af13-9923efcd9298",
   "metadata": {},
   "source": [
    "#### 4.2.1. Escalar\n",
    "\n",
    "El caso más sencillo ocurre cuando entrada, peso y sesgo son valores escalares.\n",
    "\n",
    "- $ y = wx + b$\n",
    "\n",
    "En este caso debe ser claro que la derivada parcial de la salida $y$ respecto al peso $w$ es igual a la entrada $x$. Es decir, cuando se incrementa el peso en una unidad se incrementa la salida de manera proporcional a la entrada por la que se encuentra multiplicado el peso.\n",
    "\n",
    "- $ \\cfrac{\\partial y}{\\partial w} = x $\n",
    "\n",
    "Sustituyendo en la regla de la cadena se encuentra la derivada parcial de la pérdida respecto al peso.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w} = \\cfrac{\\partial L}{\\partial y} \\cfrac{\\partial y}{\\partial w} = \\cfrac{\\partial L}{\\partial y} x $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ w \\in \\mathbb{R} $\n",
    "\n",
    "- $ x \\in \\mathbb{R} $\n",
    "\n",
    "- $ b \\in \\mathbb{R} $\n",
    "\n",
    "- $ y \\in \\mathbb{R} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53196e64-011d-4538-84d1-e1c19314526b",
   "metadata": {},
   "source": [
    "#### 4.2.2. Vectorial\n",
    "\n",
    "Cuando la entrada es un vector, el gradiente de la pérdida respecto a la salida (valor de entrada) es un vector.\n",
    "\n",
    "- $ \\nabla_Y{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el gradiente de la pérdida respecto a los pesos (valor a calcular) es una matriz.\n",
    "\n",
    "- $ \\nabla_W{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial w_{1,1}} & \\cfrac{\\partial L}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial w_{2,1}} & \\cfrac{\\partial L}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial w_{m,1}} & \\cfrac{\\partial L}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Donde cada elemento de la matriz puede calcularse de manera individual utilizando la regla de la cadena para varias variables.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_p} \\cfrac{\\partial y_p}{\\partial w_{i,j}} \\quad \\bf{(1)} $\n",
    "\n",
    "Recordando cómo se calcula la salida cuando las entradas son vectores.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "y_1\n",
    "\\\\ y_2\n",
    "\\\\ \\vdots\n",
    "\\\\ y_m\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1}\n",
    "\\\\ x_{2}\n",
    "\\\\ \\vdots\n",
    "\\\\ x_{n}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1\n",
    "\\\\ b_2\n",
    "\\\\ \\vdots\n",
    "\\\\ b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y desarrollando cada elemento, puede entenderse como afecta cada peso en el cálculo de cada salida.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "w_{1,1} x_1 + w_{1,2} x_2 + \\ldots + w_{1,n} x_n + b_1\n",
    "\\\\ w_{2,1} x_1 + w_{2,2} x_2 + \\ldots + w_{2,n} x_n + b_2\n",
    "\\\\ \\vdots\n",
    "\\\\ w_{m,1} x_1 + w_{m,2} x_2 + \\ldots + w_{m,n} x_n + b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Debe ser claro que cuando se incrementa un peso en una unidad se incrementan las salidas donde interviene dicho peso de manera proporcional a la entrada por la que se encuentra multiplicado el peso. Es decir, que la derivada parcial de una salida con respecto al peso es igual a la entrada por la que se encuentra multiplicado dicho peso. No obstante, calcular todas las derivadas parciales requiere construir un tensor para cada una de las $m$ salidas con respecto a cada uno de los $m \\times n$ pesos, lo que puede ser computacionalmente ineficiente.\n",
    "\n",
    "- $ \\cfrac{\\partial Y}{\\partial W} \\in \\mathbb{R}^{m \\times m \\times n} $\n",
    "\n",
    "Abusando quizás un poco de la notación, se pueden examinar algunas de estas derivadas parciales.\n",
    "\n",
    "- $ \\cfrac{\\partial y_1}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_1}{\\partial w_{1,1}} & \\cfrac{\\partial y_1}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_1}{\\partial w_{2,1}} & \\cfrac{\\partial y_1}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_1}{\\partial w_{m,1}} & \\cfrac{\\partial y_1}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_2}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_2}{\\partial w_{1,1}} & \\cfrac{\\partial y_2}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_2}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_2}{\\partial w_{2,1}} & \\cfrac{\\partial y_2}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_2}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_2}{\\partial w_{m,1}} & \\cfrac{\\partial y_2}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_2}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_m}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_m}{\\partial w_{1,1}} & \\cfrac{\\partial y_m}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_m}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_m}{\\partial w_{2,1}} & \\cfrac{\\partial y_m}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_m}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_m}{\\partial w_{m,1}} & \\cfrac{\\partial y_m}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_m}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Desarrollando los elementos, se observan dos patrones.\n",
    "\n",
    "- $ \\cfrac{\\partial y_1}{\\partial W} = \\begin{bmatrix}\n",
    "x_1 & x_2 & \\ldots & x_n\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_2}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ x_1 & x_2 & \\ldots & x_n\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_m}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_1 & x_2 & \\ldots & x_n\n",
    "\\end{bmatrix} $\n",
    "\n",
    "El primer patrón se observa fila a fila, donde los únicos elementos distintos de cero se encuentran en las filas donde el primer subíndice de las salidas ($p$) coincide con el índice de los pesos ($i$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{\\color{magenta}{1}}}{\\partial w_{{\\color{magenta}{1}},1}} & \\cfrac{\\partial y_{\\color{magenta}{1}}}{\\partial w_{{\\color{magenta}{1}},2}} & \\ldots & \\cfrac{\\partial y_{\\color{magenta}{1}}}{\\partial w_{{\\color{magenta}{1}},n}}\n",
    "\\\\ \\cfrac{\\partial y_1}{\\partial w_{2,1}} & \\cfrac{\\partial y_1}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_1}{\\partial w_{m,1}} & \\cfrac{\\partial y_1}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "{\\color{magenta}{x_1}} & {\\color{magenta}{x_2}} & \\ldots & {\\color{magenta}{x_n}}\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el segundo patrón se observa en las filas con valores distintos de cero, donde el subíndice de las entradas coincide con el segundo subíndice de los pesos ($j$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_1}{\\partial w_{1,{\\color{red}{1}}}} & \\cfrac{\\partial y_1}{\\partial w_{1,{\\color{red}{2}}}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{1,{\\color{red}{n}}}}\n",
    "\\\\ \\cfrac{\\partial y_1}{\\partial w_{2,1}} & \\cfrac{\\partial y_1}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_1}{\\partial w_{m,1}} & \\cfrac{\\partial y_1}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_1}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "x_{\\color{red}{1}} & x_{\\color{red}{2}} & \\ldots & x_{\\color{red}{n}}\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Es decir, una salida $y_p$ se ve afectada por un peso $w_{i,j}$ en una cuantía igual al valor de la entrada $x_j$ por el que se encuentra multiplicado.\n",
    "\n",
    "- $ \\cfrac{\\partial y_p}{\\partial w_{i,j}} = \\begin{cases} x_j & \\text{si } p = i \\\\ 0 & \\text{en caso contrario} \\end{cases} $\n",
    "\n",
    "Sustituyendo ambos patrones en la expresión de cálculo de los elementos del gradiente buscado $\\bf{(1)}$.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_p} \\cfrac{\\partial y_p}{\\partial w_{i,j}} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\cfrac{\\partial L}{\\partial y_1} \\cfrac{\\partial y_1}{\\partial w_{i,j}} + \\cfrac{\\partial L}{\\partial y_2} \\cfrac{\\partial y_2}{\\partial w_{i,j}} + \\ldots + \\cfrac{\\partial L}{\\partial y_i} \\cfrac{\\partial y_i}{\\partial w_{i,j}} + \\ldots + \\cfrac{\\partial L}{\\partial y_m} \\cfrac{\\partial y_m}{\\partial w_{i,j}} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\cfrac{\\partial L}{\\partial y_1} 0 + \\cfrac{\\partial L}{\\partial y_2} 0 + \\ldots + \\cfrac{\\partial L}{\\partial y_i} x_j + \\ldots + \\cfrac{\\partial L}{\\partial y_m} 0 $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\cfrac{\\partial L}{\\partial y_i} x_j $\n",
    "\n",
    "Se pueden desarrollar todos los elementos del gradiente evitando el cálculo de los valores que son igual a cero y no aportan nada al resultado.\n",
    "\n",
    "- $ \\nabla_W{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial w_{1,1}} & \\cfrac{\\partial L}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial w_{2,1}} & \\cfrac{\\partial L}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial w_{m,1}} & \\cfrac{\\partial L}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1} x_1 & \\cfrac{\\partial L}{\\partial y_1} x_2 & \\ldots & \\cfrac{\\partial L}{\\partial y_1} x_n\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_2} x_1 & \\cfrac{\\partial L}{\\partial y_2} x_2 & \\ldots & \\cfrac{\\partial L}{\\partial y_2} x_n\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_m} x_1 & \\cfrac{\\partial L}{\\partial y_m} x_2 & \\ldots & \\cfrac{\\partial L}{\\partial y_m} x_n\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Expresión que puede simplificarse atendiendo a la forma de los productos.\n",
    "\n",
    "$ \\nabla_W{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_m}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_1 & x_2 & \\ldots & x_n\n",
    "\\end{bmatrix} = \\nabla_Y{L} X^T $\n",
    "\n",
    "De forma que el gradiente de la pérdida respecto a los pesos de la capa $\\nabla_W{L}$ se puede calcular como el producto del gradiente de la pérdida respecto a la salida de la capa $\\nabla_Y{L}$ por la traspuesta de la entrada de la capa $X^T$.\n",
    "\n",
    "- $ \\nabla_W{L} = \\nabla_Y{L} X^T $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ \\nabla_Y{L} \\in \\mathbb{R}^{m \\times 1} $\n",
    "\n",
    "- $ X^T \\in \\mathbb{R}^{1 \\times n} $\n",
    "\n",
    "- $ \\nabla_W{L} \\in \\mathbb{R}^{m \\times n} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f3848-34c6-4b93-9aee-df0c65e0cfa9",
   "metadata": {},
   "source": [
    "#### 4.2.3. Matricial\n",
    "\n",
    "Cuando se evalúa un _batch_ de $N$ entradas el gradiente de la pérdida respecto a la salida (parámetro de entrada) es una matriz.\n",
    "\n",
    "- $ \\nabla_Y{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} & \\cfrac{\\partial L}{\\partial y_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} & \\cfrac{\\partial L}{\\partial y_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} & \\cfrac{\\partial L}{\\partial y_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{m,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el gradiente de la pérdida respecto a los pesos (valor a calcular) es también una matriz.\n",
    "\n",
    "- $ \\nabla_W{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial w_{1,1}} & \\cfrac{\\partial L}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial w_{2,1}} & \\cfrac{\\partial L}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial w_{m,1}} & \\cfrac{\\partial L}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Donde cada elemento de la matriz puede calcularse de manera individual utilizando la regla de la cadena para varias variables.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial w_{i,j}} \\quad \\bf{(1)} $\n",
    "\n",
    "Recordando como se calcula la salida cuando la entrada es un _batch_ de vectores.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "y_{1,1} & y_{1,2} & \\ldots & y_{1,N}\n",
    "\\\\ y_{2,1} & y_{2,2} & \\ldots & y_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ y_{m,1} & y_{m,2} & \\ldots & y_{m,N}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,N}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,N}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1 & b_1 & \\ldots & b_1\n",
    "\\\\ b_2 & b_2 & \\ldots & b_2\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ b_m & b_m & \\ldots & b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y desarrollando cada elemento, puede entenderse como afecta cada peso en el cálculo de cada salida.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "w_{1,1} x_{1,1} + w_{1,2} x_{2,1} + \\ldots + w_{1,n} x_{n,1} + b_1 & w_{1,1} x_{1,2} + w_{1,2} x_{2,2} + \\ldots + w_{1,n} x_{n,2} + b_1 & \\ldots & w_{1,1} x_{1,N} + w_{1,2} x_{2,N} + \\ldots + w_{1,n} x_{n,N} + b_1\n",
    "\\\\ w_{2,1} x_{1,1} + w_{2,2} x_{2,1} + \\ldots + w_{2,n} x_{n,1} + b_2 & w_{2,1} x_{1,2} + w_{2,2} x_{2,2} + \\ldots + w_{2,n} x_{n,2} + b_2 & \\ldots & w_{2,1} x_{1,N} + w_{2,2} x_{2,N} + \\ldots + w_{2,n} x_{n,N} + b_2\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} x_{1,1} + w_{m,2} x_{2,1} + \\ldots + w_{m,n} x_{n,1} + b_m & w_{m,1} x_{1,2} + w_{m,2} x_{2,2} + \\ldots + w_{m,n} x_{n,2} + b_m & \\ldots & w_{m,1} x_{1,N} + w_{m,2} x_{2,N} + \\ldots + w_{m,n} x_{n,N} + b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Debe ser claro que cuando se incrementa un peso en una unidad se incrementan las salidas donde interviene dicho peso de manera proporcional a la entrada por la que se encuentra multiplicado el peso. Es decir, que la derivada parcial de una salida con respecto al peso es igual a la entrada por la que se encuentra multiplicado dicho peso. No obstante, calcular todas las derivadas parciales requiere construir un tensor para cada una de las $m \\times N$ salidas con respecto a cada uno de los $m \\times n$ pesos, lo que puede ser computacionalmente ineficiente.\n",
    "\n",
    "- $ \\cfrac{\\partial Y}{\\partial W} \\in \\mathbb{R}^{m \\times N \\times m \\times n} $\n",
    "\n",
    "Abusando quizás un poco de la notación, se pueden examinar algunas de estas derivadas parciales.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{1,1}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,1}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{1,1}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{1,1}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{1,1}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{1,2}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,2}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{1,2}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,2}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{1,2}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{1,2}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,2}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,2}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{1,2}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{1,2}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{1,N}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,N}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{1,N}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{1,N}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{1,N}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{1,N}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,N}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,N}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{1,N}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{1,N}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{2,1}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,1}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{2,1}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{2,1}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{2,1}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{2,1}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{2,1}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,1}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{2,1}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{2,1}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{2,2}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,2}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{2,2}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{2,2}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{2,2}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{2,2}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{2,2}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,2}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{2,2}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{2,2}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{2,N}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,N}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{2,N}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{2,N}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{2,N}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{2,N}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{2,N}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,N}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{2,N}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{2,N}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{m,1}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,1}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{m,1}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{m,1}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{m,1}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{m,1}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{m,1}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,1}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{m,1}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{m,1}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} \n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{m,2}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,2}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{m,2}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{m,2}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{m,2}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{m,2}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{m,2}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,2}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{m,2}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{m,2}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{m,N}}{\\partial W} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,N}}{\\partial w_{1,1}} & \\cfrac{\\partial y_{m,N}}{\\partial w_{1,2}} & \\ldots & \\cfrac{\\partial y_{m,N}}{\\partial w_{1,n}}\n",
    "\\\\ \\cfrac{\\partial y_{m,N}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{m,N}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{m,N}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,N}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{m,N}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{m,N}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Desarrollando los elementos, se observan dos patrones.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{1,1}}{\\partial W} = \\begin{bmatrix}\n",
    "x_{1,1} & x_{2,1} & \\ldots & x_{n,1}\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{1,2}}{\\partial W} = \\begin{bmatrix}\n",
    "x_{1,2} & x_{2,2} & \\ldots & x_{n,2}\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{1,N}}{\\partial W} = \\begin{bmatrix}\n",
    "x_{1,N} & x_{2,N} & \\ldots & x_{n,N}\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{2,1}}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ x_{1,1} & x_{2,1} & \\ldots & x_{n,1}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{2,2}}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ x_{1,2} & x_{2,2} & \\ldots & x_{n,2}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{2,N}}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ x_{1,N} & x_{2,N} & \\ldots & x_{n,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{m,1}}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{1,1} & x_{2,1} & \\ldots & x_{n,1}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{m,2}}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{1,2} & x_{2,2} & \\ldots & x_{n,2}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{m,N}}{\\partial W} = \\begin{bmatrix}\n",
    "0 & 0 & \\ldots & 0\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{1,N} & x_{2,N} & \\ldots & x_{n,N}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "El primer patrón se observa fila a fila, donde los únicos elementos distintos de cero se encuentran en las filas donde el primer subíndice de las salidas ($p$) coincide con el primer subíndice de los pesos ($i$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{{\\color{magenta}{1}},1}}{\\partial w_{{\\color{magenta}{1}},1}} & \\cfrac{\\partial y_{{\\color{magenta}{1}},1}}{\\partial w_{{\\color{magenta}{1}},2}} & \\ldots & \\cfrac{\\partial y_{{\\color{magenta}{1}},1}}{\\partial w_{{\\color{magenta}{1}},n}}\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{1,1}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{1,1}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\color{magenta}{x_{1,1}} & \\color{magenta}{x_{2,1}} & \\ldots & \\color{magenta}{x_{n,1}}\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el segundo patrón se observa en las filas con valores distintos de cero, donde el primer subindice de las entradas coincide con el segundo subíndice de los pesos ($j$), y el segundo subíndice de las entradas coincide con el segundo subíndice de las salidas ($q$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,{\\color{blue}{1}}}}{\\partial w_{1,{\\color{red}{1}}}} & \\cfrac{\\partial y_{1,{\\color{blue}{1}}}}{\\partial w_{1,{\\color{red}{2}}}} & \\ldots & \\cfrac{\\partial y_{1,{\\color{blue}{1}}}}{\\partial w_{1,{\\color{red}{n}}}}\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial w_{2,1}} & \\cfrac{\\partial y_{1,1}}{\\partial w_{2,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial w_{2,n}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial w_{m,1}} & \\cfrac{\\partial y_{1,1}}{\\partial w_{m,2}} & \\ldots & \\cfrac{\\partial y_{1,1}}{\\partial w_{m,n}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "x_{{\\color{red}{1}},{\\color{blue}{1}}} & x_{{\\color{red}{2}},{\\color{blue}{1}}} & \\ldots & x_{{\\color{red}{n}},{\\color{blue}{1}}}\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Es decir, una salida $y_{p,q}$ se ve afectada por un peso $w_{i,j}$ en una cuantía igual al valor de la entrada $x_{j,q}$ por el que se encuentra multiplicado.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{p,q}}{\\partial w_{i,j}} = \\begin{cases} x_{j,q} & \\text{si } p = i \\\\ 0 & \\text{en caso contrario} \\end{cases} $\n",
    "\n",
    "Sustituyendo ambos patrones en la expresión de cálculo de los elementos del gradiente buscado $\\bf{(1)}$.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial w_{i,j}} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{p=1}^{m} \\left( \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial w_{i,j}} \\right) $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{i,q}} \\cfrac{\\partial y_{i,q}}{\\partial w_{i,j}} + \\displaystyle\\sum_{\\substack{p=1 \\\\ p \\ne i}}^{m} \\left( \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial w_{i,j}} \\right) $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{i,q}} \\cfrac{\\partial y_{i,q}}{\\partial w_{i,j}} + 0 $\n",
    " \n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{i,q}} x_{j,q} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial w_{i,j}} = \\cfrac{\\partial L}{\\partial y_{i,1}} x_{j,1} + \\cfrac{\\partial L}{\\partial y_{i,2}} x_{j,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{i,N}} x_{j,N} $\n",
    "\n",
    "Se pueden desarrollar todos los elementos del gradiente evitando el cálculo de los valores que son igual a cero y no aportan nada al resultado.\n",
    "\n",
    "- $ \\nabla_W{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} x_{1,1} + \\cfrac{\\partial L}{\\partial y_{1,2}} x_{1,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{1,N}} x_{1,N}\n",
    "& \\cfrac{\\partial L}{\\partial y_{1,1}} x_{2,1} + \\cfrac{\\partial L}{\\partial y_{1,2}} x_{2,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{1,N}} x_{2,N}\n",
    "& \\ldots & \\cfrac{\\partial L}{\\partial y_{1,1}} x_{n,1} + \\cfrac{\\partial L}{\\partial y_{1,2}} x_{n,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{1,N}} x_{n,N}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} x_{1,1} + \\cfrac{\\partial L}{\\partial y_{2,2}} x_{1,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{2,N}} x_{1,N}\n",
    "& \\cfrac{\\partial L}{\\partial y_{2,1}} x_{2,1} + \\cfrac{\\partial L}{\\partial y_{2,2}} x_{2,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{2,N}} x_{2,N}\n",
    "& \\ldots & \\cfrac{\\partial L}{\\partial y_{2,1}} x_{n,1} + \\cfrac{\\partial L}{\\partial y_{2,2}} x_{n,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{2,N}} x_{n,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} x_{1,1} + \\cfrac{\\partial L}{\\partial y_{m,2}} x_{1,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,N}} x_{1,N}\n",
    "& \\cfrac{\\partial L}{\\partial y_{m,1}} x_{2,1} + \\cfrac{\\partial L}{\\partial y_{m,2}} w_{2,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,N}} x_{2,N}\n",
    "& \\ldots & \\cfrac{\\partial L}{\\partial y_{m,1}} x_{n,1} + \\cfrac{\\partial L}{\\partial y_{m,2}} x_{n,2} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,N}} x_{n,N}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Expresión que puede simplificarse atendiendo a la forma de los sumandos.\n",
    "\n",
    "- $ \\nabla_W{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} & \\cfrac{\\partial L}{\\partial y_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} & \\cfrac{\\partial L}{\\partial y_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} & \\cfrac{\\partial L}{\\partial y_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{m,N}}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1,1} & x_{2,1} & \\ldots & x_{n,1}\n",
    "\\\\ x_{1,2} & x_{2,2} & \\ldots & x_{n,2}\n",
    "\\\\ \\vdots\n",
    "\\\\ x_{1,N} & x_{2,N} & \\ldots & x_{n,N}\n",
    "\\end{bmatrix} = \\nabla_Y{L} X^T $\n",
    "\n",
    "De forma que el gradiente de la pérdida respecto a los pesos de la capa $\\nabla_W{L}$ se puede calcular como el producto del gradiente de la pérdida respecto a la salida de la capa $\\nabla_Y{L}$ por la traspuesta de la entrada a la capa $X^T$.\n",
    "\n",
    "- $ \\nabla_W{L} = \\nabla_Y{L} X^T $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ \\nabla_Y{L} \\in \\mathbb{R}^{m \\times N} $\n",
    "\n",
    "- $ X^T \\in \\mathbb{R}^{N \\times n} $\n",
    "\n",
    "- $ \\nabla_W{L} \\in \\mathbb{R}^{m \\times n} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5082f7-c326-40f2-8379-e570ee5ecb85",
   "metadata": {},
   "source": [
    "### 4.3. Gradiente de la Pérdida Respecto a los Sesgos\n",
    "\n",
    "El tercer resultado a calcular por el _backward pass_ es la derivada de la pérdida respecto a los sesgos de la capa.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial B} $\n",
    "\n",
    "La derivada a calcular puede encontrarse aplicando la regla de la cadena.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial B} = \\cfrac{\\partial L}{\\partial Y} \\cfrac{\\partial Y}{\\partial B} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974e0ee5-df0f-4ae0-8bce-efe2b48bd403",
   "metadata": {},
   "source": [
    "#### 4.3.1. Escalar\n",
    "\n",
    "El caso más sencillo ocurre cuando entrada, peso y sesgo son valores escalares.\n",
    "\n",
    "- $ y = wx + b$\n",
    "\n",
    "En este caso debe ser claro que la derivada parcial de la salida $y$ respecto al sesgo $b$ es igual $1$. Es decir, cuando se incrementa el sesgo en una unidad se incrementa la salida en una unidad.\n",
    "\n",
    "- $ \\cfrac{\\partial y}{\\partial b} = 1 $\n",
    "\n",
    "Sustituyendo en la regla de la cadena se encuentra la derivada parcial de la pérdida respecto al sesgo.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b} = \\cfrac{\\partial L}{\\partial y} \\cfrac{\\partial y}{\\partial b} = \\cfrac{\\partial L}{\\partial y} $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ w \\in \\mathbb{R} $\n",
    "\n",
    "- $ x \\in \\mathbb{R} $\n",
    "\n",
    "- $ b \\in \\mathbb{R} $\n",
    "\n",
    "- $ y \\in \\mathbb{R} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3797ad70-187f-4ccf-9f46-c6aaf1335a41",
   "metadata": {},
   "source": [
    "#### 4.3.2. Vectorial\n",
    "\n",
    "Cuando la entrada es un vector, el gradiente de la pérdida respecto a la salida (valor de entrada) es un vector.\n",
    "\n",
    "- $ \\nabla_Y{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el gradiente de la pérdida respecto a los pesos (valor a calcular) es también un vector.\n",
    "\n",
    "- $ \\nabla_B{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Donde cada elemento del vector puede calcularse de manera individual utilizando la regla de la cadena para varias variables.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_p} \\cfrac{\\partial y_p}{\\partial b_i} \\quad \\bf{(1)} $\n",
    "\n",
    "Recordando cómo se calcula la salida cuando las entradas son vectores.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "y_1\n",
    "\\\\ y_2\n",
    "\\\\ \\vdots\n",
    "\\\\ y_m\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1}\n",
    "\\\\ x_{2}\n",
    "\\\\ \\vdots\n",
    "\\\\ x_{n}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1\n",
    "\\\\ b_2\n",
    "\\\\ \\vdots\n",
    "\\\\ b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y desarrollando cada elemento, puede entenderse como afecta cada sesgo en el cálculo de cada salida.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "w_{1,1} x_1 + w_{1,2} x_2 + \\ldots + w_{1,n} x_n + b_1\n",
    "\\\\ w_{2,1} x_1 + w_{2,2} x_2 + \\ldots + w_{2,n} x_n + b_2\n",
    "\\\\ \\vdots\n",
    "\\\\ w_{m,1} x_1 + w_{m,2} x_2 + \\ldots + w_{m,n} x_n + b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Debe ser claro que cuando se incrementa un sesgo en una unidad se incrementa la salida donde interviene dicho sesgo en una unidad. Es decir, que la derivada parcial de la salida con respecto al sesgo es igual a $1$. De forma que puede calcularse una derivada parcial por cada una de las $m$ salidas con respecto a cada una de los $m$ sesgos. Derivadas parciales que pueden reunirse en una matriz, llamada matriz jacobiana.\n",
    "\n",
    "- $ \\cfrac{\\partial Y}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_1}{\\partial b_1} & \\cfrac{\\partial y_1}{\\partial b_2} & \\ldots & \\cfrac{\\partial y_1}{\\partial b_m}\n",
    "\\\\ \\cfrac{\\partial y_2}{\\partial b_1} & \\cfrac{\\partial y_2}{\\partial b_2} & \\ldots & \\cfrac{\\partial y_2}{\\partial b_m}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_m}{\\partial b_1} & \\cfrac{\\partial y_m}{\\partial b_2} & \\ldots & \\cfrac{\\partial y_m}{\\partial b_m}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "1 & 0 & \\ldots & 0\n",
    "\\\\ 0 & 1 & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & 1\n",
    "\\end{bmatrix} = I $\n",
    "\n",
    "Analizando los valores de la matriz, se observa un patrón en la posición de los elementos que son distintos de cero, donde el subíndice de las salidas ($p$) coincide con el subíndice de los sesgos ($i$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{\\color{magenta}{1}}}{\\partial b_{\\color{magenta}{1}}} & \\cfrac{\\partial y_1}{\\partial b_2} & \\ldots & \\cfrac{\\partial y_1}{\\partial b_m}\n",
    "\\\\ \\cfrac{\\partial y_2}{\\partial b_1} & \\cfrac{\\partial y_{\\color{magenta}{2}}}{\\partial b_{\\color{magenta}{2}}} & \\ldots & \\cfrac{\\partial y_2}{\\partial b_m}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial y_m}{\\partial b_1} & \\cfrac{\\partial y_m}{\\partial b_2} & \\ldots & \\cfrac{\\partial y_{\\color{magenta}{m}}}{\\partial b_{\\color{magenta}{m}}}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\color{magenta}{1} & 0 & \\ldots & 0\n",
    "\\\\ 0 & \\color{magenta}{1} & \\ldots & 0\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ 0 & 0 & \\ldots & \\color{magenta}{1}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Es decir, una salida $y_p$ se ve afectada por un sesgo $b_i$ en una cuantía igual a 1.\n",
    "\n",
    "- $ \\cfrac{\\partial y_p}{\\partial b_i} = \\begin{cases} 1 & \\text{si } p = i \\\\ 0 & \\text{en caso contrario} \\end{cases} $\n",
    "\n",
    "Sustituyendo en la expresión de cálculo de los elementos del gradiente buscado $\\bf{(1)}$.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{p=1}^{m} \\cfrac{\\partial L}{\\partial y_p} \\cfrac{\\partial y_p}{\\partial b_i} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\cfrac{\\partial L}{\\partial y_1} \\cfrac{\\partial y_1}{\\partial b_i} + \\cfrac{\\partial L}{\\partial y_2} \\cfrac{\\partial y_2}{\\partial b_i} + \\ldots + \\cfrac{\\partial L}{\\partial y_i} \\cfrac{\\partial y_i}{\\partial b_i} + \\ldots + \\cfrac{\\partial L}{\\partial y_m} \\cfrac{\\partial y_m}{\\partial b_i} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\cfrac{\\partial L}{\\partial y_1} 0 + \\cfrac{\\partial L}{\\partial y_2} 0 + \\ldots + \\cfrac{\\partial L}{\\partial y_i} 1 + \\ldots + \\cfrac{\\partial L}{\\partial y_m} 0 $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\cfrac{\\partial L}{\\partial y_i} $\n",
    "\n",
    "Se pueden desarrollar todos los elementos del gradiente evitando el cálculo de los valores que son igual a cero y no aportan nada al resultado.\n",
    "\n",
    "- $ \\nabla_B{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_m}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_m}\n",
    "\\end{bmatrix} = \\nabla_Y{L} $\n",
    "\n",
    "De forma que el gradiente de la pérdida respecto a los sesgos de la capa $\\nabla_B{L}$ es igual al gradiente de la pérdida respecto a la salida de la capa $\\nabla_Y{L}$.\n",
    "\n",
    "- $ \\nabla_B{L} = \\nabla_Y{L} $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ \\nabla_Y{L} \\in \\mathbb{R}^{m \\times 1} $\n",
    "\n",
    "- $ \\nabla_B{L} \\in \\mathbb{R}^{m \\times 1} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14904198-c16c-4dd4-9854-58decaf3261a",
   "metadata": {},
   "source": [
    "#### 4.3.3. Matricial\n",
    "\n",
    "Cuando se evalúa un _batch_ de $N$ entradas, el gradiente de la pérdida respecto a la salida (valor de entrada) es una matriz.\n",
    "\n",
    "- $ \\nabla_Y{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} & \\cfrac{\\partial L}{\\partial y_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} & \\cfrac{\\partial L}{\\partial y_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} & \\cfrac{\\partial L}{\\partial y_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{m,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y el gradiente de la pérdida respecto a los pesos (valor a calcular) es un vector.\n",
    "\n",
    "- $ \\nabla_B{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Donde cada elemento del vector puede calcularse de manera individual utilizando la regla de la cadena para varias variables.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{p=1}^{m} \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial b_i} \\quad \\bf{(1)} $\n",
    "\n",
    "Recordando como se calcula la salida cuando la entrada es un _batch_ de vectores.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "y_{1,1} & y_{1,2} & \\ldots & y_{1,N}\n",
    "\\\\ y_{2,1} & y_{2,2} & \\ldots & y_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ y_{m,1} & y_{m,2} & \\ldots & y_{m,N}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "w_{1,1} & w_{1,2} & \\ldots & w_{1,n}\n",
    "\\\\ w_{2,1} & w_{2,2} & \\ldots & w_{2,n}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} & w_{m,2} & \\ldots & w_{m,n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "x_{1,1} & x_{1,2} & \\ldots & x_{1,N}\n",
    "\\\\ x_{2,1} & x_{2,2} & \\ldots & x_{2,N}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ x_{n,1} & x_{n,2} & \\ldots & x_{n,N}\n",
    "\\end{bmatrix} + \\begin{bmatrix}\n",
    "b_1 & b_1 & \\ldots & b_1\n",
    "\\\\ b_2 & b_2 & \\ldots & b_2\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ b_m & b_m & \\ldots & b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Y desarrollando cada elemento, puede entenderse como afecta cada sesgo en el cálculo de cada salida.\n",
    "\n",
    "- $ Y = \\begin{bmatrix}\n",
    "w_{1,1} x_{1,1} + w_{1,2} x_{2,1} + \\ldots + w_{1,n} x_{n,1} + b_1 & w_{1,1} x_{1,2} + w_{1,2} x_{2,2} + \\ldots + w_{1,n} x_{n,2} + b_1 & \\ldots & w_{1,1} x_{1,N} + w_{1,2} x_{2,N} + \\ldots + w_{1,n} x_{n,N} + b_1\n",
    "\\\\ w_{2,1} x_{1,1} + w_{2,2} x_{2,1} + \\ldots + w_{2,n} x_{n,1} + b_2 & w_{2,1} x_{1,2} + w_{2,2} x_{2,2} + \\ldots + w_{2,n} x_{n,2} + b_2 & \\ldots & w_{2,1} x_{1,N} + w_{2,2} x_{2,N} + \\ldots + w_{2,n} x_{n,N} + b_2\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ w_{m,1} x_{1,1} + w_{m,2} x_{2,1} + \\ldots + w_{m,n} x_{n,1} + b_m & w_{m,1} x_{1,2} + w_{m,2} x_{2,2} + \\ldots + w_{m,n} x_{n,2} + b_m & \\ldots & w_{m,1} x_{1,N} + w_{m,2} x_{2,N} + \\ldots + w_{m,n} x_{n,N} + b_m\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Debe ser claro que cuando se incrementa un sesgo en una unidad se incrementan las salidas donde interviene dicho sesgo en una unidad. Es decir, que la derivada parcial de una salida con respecto al sesgo es igual a $1$. No obstante, calcular todas las derivadas parciales requiere construir un tensor para cada una de las $m \\times N$ salidas con respecto a cada uno de los $m$ sesgos, lo que puede ser computacionalmente ineficiente.\n",
    "\n",
    "- $ \\cfrac{\\partial Y}{\\partial B} \\in \\mathbb{R}^{m \\times N \\times m} $\n",
    "\n",
    "Abusando quizás un poco de la notación, se pueden examinar algunas de estas derivadas parciales.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{1,1}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,1}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial b_m}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{1,2}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,2}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{1,2}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,2}}{\\partial b_m}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{1,N}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{1,N}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{1,N}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,N}}{\\partial b_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{2,1}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,1}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{2,1}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,1}}{\\partial b_m}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{2,2}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,2}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{2,2}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,2}}{\\partial b_m}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{2,N}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{2,N}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{2,N}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{2,N}}{\\partial b_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{m,1}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,1}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{m,1}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,1}}{\\partial b_m}\n",
    "\\end{bmatrix}\n",
    "\\qquad\n",
    "\\cfrac{\\partial y_{m,2}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,2}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{m,2}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,2}}{\\partial b_m}\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots \\qquad\n",
    "\\cfrac{\\partial y_{m,N}}{\\partial B} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{m,N}}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial y_{m,N}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{m,N}}{\\partial b_m}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Desarrollando los elementos, se observa un patrón.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{1,1}}{\\partial B} = \\begin{bmatrix}\n",
    "1\n",
    "\\\\ 0\n",
    "\\\\ \\vdots\n",
    "\\\\ 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{1,2}}{\\partial B} = \\begin{bmatrix}\n",
    "1\n",
    "\\\\ 0\n",
    "\\\\ \\vdots\n",
    "\\\\ 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{1,N}}{\\partial B} = \\begin{bmatrix}\n",
    "1\n",
    "\\\\ 0\n",
    "\\\\ \\vdots\n",
    "\\\\ 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{2,1}}{\\partial B} = \\begin{bmatrix}\n",
    "0\n",
    "\\\\ 1\n",
    "\\\\ \\vdots\n",
    "\\\\ 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{2,2}}{\\partial B} = \\begin{bmatrix}\n",
    "0\n",
    "\\\\ 1\n",
    "\\\\ \\vdots\n",
    "\\\\ 0\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{2,N}}{\\partial B} = \\begin{bmatrix}\n",
    "0\n",
    "\\\\ 1\n",
    "\\\\ \\vdots\n",
    "\\\\ 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "$ \\qquad \\vdots $\n",
    "\n",
    "- $ \\cfrac{\\partial y_{m,1}}{\\partial B} = \\begin{bmatrix}\n",
    "0\n",
    "\\\\ 0\n",
    "\\\\ \\vdots\n",
    "\\\\ 1\n",
    "\\end{bmatrix}\n",
    "\\qquad \\cfrac{\\partial y_{m,2}}{\\partial B} = \\begin{bmatrix}\n",
    "0\n",
    "\\\\ 0\n",
    "\\\\ \\vdots\n",
    "\\\\ 1\n",
    "\\end{bmatrix}\n",
    "\\qquad \\ldots\n",
    "\\qquad \\cfrac{\\partial y_{m,N}}{\\partial B} = \\begin{bmatrix}\n",
    "0\n",
    "\\\\ 0\n",
    "\\\\ \\vdots\n",
    "\\\\ 1\n",
    "\\end{bmatrix} $\n",
    "\n",
    "El patrón se observa fila a fila, donde los únicos elementos distintos de cero se encuentran en las filas donde el subíndice de las salidas ($p$) coincide con el primer subíndice de los sesgos ($i$). Ejemplo:\n",
    "\n",
    "- $ \\begin{bmatrix}\n",
    "\\cfrac{\\partial y_{{\\color{magenta}{1}},1}}{\\partial b_{\\color{magenta}{1}}}\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial y_{1,1}}{\\partial b_m}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "{\\color{magenta}{1}}\n",
    "\\\\ 0\n",
    "\\\\ \\vdots\n",
    "\\\\ 0\n",
    "\\end{bmatrix} $\n",
    "\n",
    "Es decir, una salida $y_{p,q}$ se ve afectada por un sesgo $b_i$ en una cuantía igual a 1.\n",
    "\n",
    "- $ \\cfrac{\\partial y_{p,q}}{\\partial b_i} = \\begin{cases} 1 & \\text{si } p = i \\\\ 0 & \\text{en caso contrario} \\end{cases} $\n",
    "\n",
    "Sustituyendo en la expresión de cálculo de los elementos del gradiente buscado $\\bf{(1)}$.\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{p=1}^{m} \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial b_i} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{p=1}^{m} \\left( \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial b_i} \\right) $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{i,q}} \\cfrac{\\partial y_{i,q}}{\\partial b_i} + \\displaystyle\\sum_{\\substack{p=1 \\\\ p \\ne i}}^{m} \\left( \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{p,q}} \\cfrac{\\partial y_{p,q}}{\\partial b_i} \\right) $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{i,q}} 1 + 0 $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i} = \\displaystyle\\sum_{q=1}^{N} \\cfrac{\\partial L}{\\partial y_{i,q}} $\n",
    "\n",
    "- $ \\cfrac{\\partial L}{\\partial b_i}= \\cfrac{\\partial L}{\\partial y_{i,1}} + \\cfrac{\\partial L}{\\partial y_{i,2}} + \\ldots + \\cfrac{\\partial L}{\\partial y_{i,N}} $\n",
    "\n",
    "Se pueden desarrollar todos los elementos del gradiente evitando el cálculo de los valores que son igual a cero y no aportan nada al resultado.\n",
    "\n",
    "- $ \\nabla_B{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial b_1}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_2}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial b_m}\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} + \\cfrac{\\partial L}{\\partial y_{1,2}} + \\ldots + \\cfrac{\\partial L}{\\partial y_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} + \\cfrac{\\partial L}{\\partial y_{2,2}} + \\ldots + \\cfrac{\\partial L}{\\partial y_{2,N}}\n",
    "\\\\ \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} + \\cfrac{\\partial L}{\\partial y_{m,2}} + \\ldots + \\cfrac{\\partial L}{\\partial y_{m,N}}\n",
    "\\end{bmatrix} $\n",
    "\n",
    "De forma que el gradiente de la pérdida respecto a los sesgos de la capa $\\nabla_B{L}$ es igual a la suma, fila a fila, de los elementos del gradiente de la pérdida respecto a la salida de la capa $\\nabla_Y{L}$.\n",
    "\n",
    "- $ \\nabla_B{L} = \\begin{bmatrix}\n",
    "\\cfrac{\\partial L}{\\partial y_{1,1}} & \\cfrac{\\partial L}{\\partial y_{1,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{1,N}}\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{2,1}} & \\cfrac{\\partial L}{\\partial y_{2,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{2,N}}\n",
    "\\\\ \\vdots & \\vdots & \\ddots & \\vdots\n",
    "\\\\ \\cfrac{\\partial L}{\\partial y_{m,1}} & \\cfrac{\\partial L}{\\partial y_{m,2}} & \\ldots & \\cfrac{\\partial L}{\\partial y_{m,N}}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "1\n",
    "\\\\ 1 \n",
    "\\\\ \\vdots\n",
    "\\\\ 1 \\end{bmatrix} = \\nabla_Y{L} \\mathbf{1} $\n",
    "\n",
    "Dimensiones:\n",
    "\n",
    "- $ \\nabla_Y{L} \\in \\mathbb{R}^{m \\times N} $\n",
    "\n",
    "- $ \\mathbf{1} \\in \\mathbb{R}^{N \\times 1} $\n",
    "\n",
    "- $ \\nabla_B{L} \\in \\mathbb{R}^{m \\times 1} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ac337-aefe-4961-9163-70c1e8ef7b9f",
   "metadata": {},
   "source": [
    "## 5. Código Fuente\n",
    "\n",
    "A continuación se desarrolla una capa de una red neuronal que implementa una transformación afín.\n",
    "\n",
    "El desarrollo se realiza a bajo nivel, evitando el uso de _frameworks_ y librerías externas en la medida de lo posible, lo que en la práctica no es útil ni necesario, pero que resulta interesante como ejercicio para afianzar conceptos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f62f92-b101-4e50-bd58-02cca2ba05ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3e270a-77f3-483c-8ead-6dd2932ef76e",
   "metadata": {},
   "source": [
    "### 5.1. AffineLayer\n",
    "\n",
    "La capa es una implementación directa de las expresiones matemáticas correspondientes para poder evaluar una o varias entradas a un mismo tiempo.\n",
    "\n",
    "- $ Y = W X + B $\n",
    "\n",
    "- $ \\nabla_X{L} = W^T \\nabla_Y{L} $\n",
    "\n",
    "- $ \\nabla_W{L} = \\nabla_Y{L} X^T $\n",
    "\n",
    "- $ \\nabla_B{L} = \\nabla_Y{L} \\mathbf{1} $\n",
    "\n",
    "En el _forward pass_ hay que destacar que no es necesario construir la matriz de sesgos repitiendo los mismos valores una y otra vez. La librería numérica _numpy_ es capaz de realizar operaciones entre matrices y vectores aunque no tengan el tamaño esperado aplicando una técnica denominada _broadcasting_.\n",
    "\n",
    "Por su parte, en el _backward pass_, la suma de los valores de los sesgos se realiza fila a fila gracias al atributo ```axis``` de _numpy_, que permite especificar sobre cual dimensión hay que realizar la operación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83473a31-8ae0-4b46-9901-ebd89671d53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineLayer():\n",
    "\n",
    "    def __init__(self, n, m):\n",
    "        self.n = n\n",
    "        self.m = m\n",
    "\n",
    "    def forward(self, x, params):\n",
    "        w = params['w']\n",
    "        b = params['b']\n",
    "\n",
    "        y = w @ x + b\n",
    "\n",
    "        params['x'] = x\n",
    "\n",
    "        return y\n",
    "\n",
    "    def backward(self, dy, params):\n",
    "        x = params['x']\n",
    "        w = params['w']\n",
    "\n",
    "        dx = w.T @ dy\n",
    "        dw = dy @ x.T\n",
    "        db = np.sum(dy, axis=1, keepdims=True)\n",
    "\n",
    "        params['dw'] = dw\n",
    "        params['db'] = db\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830b604-75bb-4581-a3bb-82ba0a502b0c",
   "metadata": {},
   "source": [
    "## 6. Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28c2c42-8f14-4010-9824-f41f752e37be",
   "metadata": {},
   "source": [
    "### 6.1. AffineLayer\n",
    "\n",
    "La capa debe realizar los cálculos y retornar los valores con las dimensiones esperadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31cce05-d54d-43b9-8ca1-0060808e56af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_affine_layer():\n",
    "    layer = AffineLayer(n=3, m=2)\n",
    "\n",
    "    params = {}\n",
    "    params['w'] = np.array([[11, 12, 13], [14, 15, 16]])\n",
    "    params['b'] = np.array([[21], [22]])\n",
    "\n",
    "    '''\n",
    "    Forward Pass\n",
    "    '''\n",
    "\n",
    "    x = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "\n",
    "    y = layer.forward(x, params)\n",
    "\n",
    "    assert params['w'].shape == (2, 3)\n",
    "    assert params['x'].shape == (3, 3)\n",
    "    assert params['b'].shape == (2, 1)\n",
    "    assert y.shape == (2, 3)\n",
    "\n",
    "    assert np.allclose(\n",
    "        y,\n",
    "        np.array([\n",
    "            [11 * 1 + 12 * 4 + 13 * 7 + 21, 11 * 2 + 12 * 5 + 13 * 8 + 21, 11 * 3 + 12 * 6 + 13 * 9 + 21],\n",
    "            [14 * 1 + 15 * 4 + 16 * 7 + 22, 14 * 2 + 15 * 5 + 16 * 8 + 22, 14 * 3 + 15 * 6 + 16 * 9 + 22]\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    '''\n",
    "    Backward Pass\n",
    "    '''\n",
    "\n",
    "    dy = np.array([[31, 32, 33], [34, 35, 36]])\n",
    "\n",
    "    dx = layer.backward(dy, params)\n",
    "\n",
    "    assert dx.shape == (3, 3)\n",
    "    assert params['dw'].shape == (2, 3)\n",
    "    assert params['db'].shape == (2, 1)\n",
    "    \n",
    "    assert np.allclose(\n",
    "        dx,\n",
    "        np.array([\n",
    "            [11 * 31 + 14 * 34, 11 * 32 + 14 * 35, 11 * 33 + 14 * 36],\n",
    "            [12 * 31 + 15 * 34, 12 * 32 + 15 * 35, 12 * 33 + 15 * 36],\n",
    "            [13 * 31 + 16 * 34, 13 * 32 + 16 * 35, 13 * 33 + 16 * 36]\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    assert np.allclose(\n",
    "        params['dw'],\n",
    "        np.array([\n",
    "            [31 * 1 + 32 * 2 + 33 * 3, 31 * 4 + 32 * 5 + 33 * 6, 31 * 7 + 32 * 8 + 33 * 9],\n",
    "            [34 * 1 + 35 * 2 + 36 * 3, 34 * 4 + 35 * 5 + 36 * 6, 34 * 7 + 35 * 8 + 36 * 9]\n",
    "        ])\n",
    "    )\n",
    "\n",
    "    assert np.allclose(\n",
    "        params['db'],\n",
    "        np.array([\n",
    "            [31 + 32 + 33],\n",
    "            [34 + 35 + 36]\n",
    "        ])\n",
    "    )\n",
    "\n",
    "test_affine_layer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
