{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20d06a05-6f2a-45da-ae65-266241246ad8",
   "metadata": {},
   "source": [
    "# Hierarchical Reasoning Model\n",
    "\n",
    "Revisión informal de \"_Hierarchical Reasoning Model_\" (_HRM_).\n",
    "\n",
    "Arquitectura publicada en junio de 2025.\n",
    "\n",
    "- [https://arxiv.org/pdf/2506.21734](https://arxiv.org/pdf/2506.21734)\n",
    "\n",
    "Permite la creación de modelos de reducido tamaño que resuelven tareas específicas con pocos ejemplos y sin preentrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56564979-151e-428e-b83a-62d63ee0fd52",
   "metadata": {},
   "source": [
    "## 1. Arquitectura\n",
    "\n",
    "La arquitectura se compone de dos módulos.\n",
    "\n",
    "```\n",
    "High-Level (H)\n",
    "```\n",
    "\n",
    "Un módulo _H_ de alto nivel (_High-Level_) para el razonamiento abstracto que dirige la estrategia.\n",
    "\n",
    "```\n",
    "Low-Level (L)\n",
    "```\n",
    "\n",
    "Y un módulo _L_ de bajo nivel (_Low-Level_) para los cálculos detallados, como búsquedas intensivas o refinamientos.\n",
    "\n",
    "El _paper_ presenta resultados experimentales de modelos siguiendo esta arquitectura con apenas 27 millones de parámetros y entrenados con unos escasos 1.000 ejemplos que son capaces de resolver _sudokus_ o encontrar la ruta óptima de salida de laberintos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6a885a-9d72-4935-b73e-c84ab4020277",
   "metadata": {},
   "source": [
    "## 2. Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b48ebb-0906-4fa0-afef-adb3c788d0a3",
   "metadata": {},
   "source": [
    "### 2.1. Componentes\n",
    "\n",
    "El modelo propuesto por la arquitectura se estructura en cuatro componentes entrenables.\n",
    "\n",
    "- Una red de entrada $f_I(\\cdot ; \\theta_I)$.\n",
    "\n",
    "- Un módulo recurrente de bajo nivel $f_L(\\cdot ; \\theta_L)$.\n",
    "\n",
    "- Un módulo recurrente de alto nivel $f_H(\\cdot ; \\theta_H)$.\n",
    "\n",
    "- Una red de salida $f_O(\\cdot ; \\theta_O)$.\n",
    "\n",
    "Donde $\\theta$ representa los parámetros entrenables de cada componente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbae6c04-f4e5-4d79-ab21-d5c19fcc1703",
   "metadata": {},
   "source": [
    "### 2.2. Ciclos\n",
    "\n",
    "```\n",
    "N x High-Level x T x Low-Level\n",
    "```\n",
    "\n",
    "El modelo opera realizando $N$ ciclos de alto nivel, cada uno de ellos compuesto de $T$ pasos de bajo nivel.\n",
    "\n",
    "- $ i = 1, \\ldots, N \\times T $\n",
    "\n",
    "Los módulos _L_ y _H_ tienen un estado oculto $z_L^i$ y $z_H^i$, que es inicializado con un vector $z_L^0$ y $z_H^0$, respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf71ed7-2b03-45ed-888d-d5ef23394e90",
   "metadata": {},
   "source": [
    "### 2.3. Forward Pass\n",
    "\n",
    "La red de entrada proyecta un vector de entrada $x$ en otro vector $\\tilde{x}$.\n",
    "\n",
    "- $ \\tilde{x} = f_I(x ; \\theta_I) $\n",
    "\n",
    "En cada paso $i$ el módulo _L_ se actualiza en función de su estado anterior, el estado anterior de _H_, y la entrada.\n",
    "\n",
    "- $ z_L^i = f_L(z_L^{i-1}, z_H^{i-1}, \\tilde{x}; \\theta_L) $\n",
    "\n",
    "Y el módulo _H_ se actualiza cada $T$ pasos en función de su estado anterior, y el estado de _L_.\n",
    "\n",
    "- $ z_H^i = \\begin{cases}\n",
    "f_H(z_H^{i-1}, z_L^i; \\theta_H) & \\text{si} & (i \\mod T) = 0,\n",
    "\\\\ z_H^{i-1} & \\text{en} & \\text{caso contrario.}\n",
    "\\end{cases} $\n",
    "\n",
    "Después de $N$ ciclos completos, de $T$ pasos cada uno, la red de salida obtiene un vector con la predición $\\tilde{y}$ en función del estado del módulo _H_.\n",
    "\n",
    "- $ \\tilde{y} = f_O(z_H^{NT} ; \\theta_O) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04df1f4-d9a1-44de-bf86-b952cb434432",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f556337-12e4-4ee3-a27e-8b8147293aa2",
   "metadata": {},
   "source": [
    "### 3.1. Backward Pass\n",
    "\n",
    "Una red recurrente tradicional requiere almacenar los estados ocultos de cada paso para poder combinarlos posteriormente con los gradientes durante el _backward pass_, lo que impone $O(T)$ requerimientos de memoria para $T$ pasos.\n",
    "\n",
    "_HRM_ utiliza únicamente el estado oculto de cada módulo en el último paso, lo que impone sólo $O(1)$ requerimientos de memoria.\n",
    "\n",
    "El marco teórico del _paper_ establece que, si el módulo _L_ converge a un punto fijo local $z_L^\\star$, entonces, aplicando resultados conocidos de _Deep Equilibrium Models_ (_DEQ_) basados en _Implicit Function Theorem_ (_IFT_), se pueden calcular aproximaciones a los gradientes utilizando sólo los últimos estados.\n",
    "\n",
    "- $ \\dfrac{\\partial{z_L^\\star}}{\\partial{\\theta_L}} \\approx \\dfrac{\\partial{f_L}}{\\partial{\\theta_L}}, \\quad\n",
    "\\dfrac{\\partial{z_L^\\star}}{\\partial{\\theta_I}} \\approx \\dfrac{\\partial{f_L}}{\\partial{\\theta_I}} $\n",
    "\n",
    "Y de igual forma para el módulo _H_.\n",
    "\n",
    "- $ \\dfrac{\\partial{z_H^\\star}}{\\partial{\\theta_H}} \\approx \\dfrac{\\partial{f_H}}{\\partial{\\theta_H}}, \\quad\n",
    "\\dfrac{\\partial{z_H^\\star}}{\\partial{\\theta_L}} \\approx \\dfrac{\\partial{f_H}}{\\partial{z_L^\\star}} \\cdot \\dfrac{\\partial{z_L^\\star}}{\\partial{\\theta_L}}, \\quad\n",
    "\\dfrac{\\partial{z_H^\\star}}{\\partial{\\theta_I}} \\approx \\dfrac{\\partial{f_H}}{\\partial{z_L^\\star}} \\cdot \\dfrac{\\partial{z_L^\\star}}{\\partial{\\theta_I}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfecded-ddaa-4144-bedf-8755e0b5c54d",
   "metadata": {},
   "source": [
    "### 3.2. Deep Supervision\n",
    "\n",
    "_HRM_ utiliza un mecanismo de _deep supervision_ para guiar la actualización de los pesos.\n",
    "\n",
    "En vez de aplicar un único _forward pass_ para cada muestra $(x, y)$ del conjunto de entrenamiento, se ejecutan $M$ _forward  pass_ llamados _segmentos_.\n",
    "\n",
    "- $ m \\in \\{1, \\ldots, M\\} $\n",
    "\n",
    "De forma que al final de cada segmento se obtiene un estado final para los módulos _H_ y _L_.\n",
    "\n",
    "- $ z^m = (z_H^{mNT}, z_L^{mNT}) $\n",
    "\n",
    "El mecanismo de _deep supervision_ calcula el estado final y la salida predicha mediante un _forward pass_ con el estado final del segmento anterior y la entrada actual.\n",
    "\n",
    "- $ (z^m, \\hat{y}^m) \\leftarrow \\operatorname{HRM}(z^{m-1}, x ; \\theta) $\n",
    "\n",
    "A continuación calcula la pérdida para el segmento actual.\n",
    "\n",
    "- $ L^m \\leftarrow \\operatorname{LOSS}(\\hat{y}^m, y) $\n",
    "\n",
    "Y actualiza los pesos con los gradientes.\n",
    "\n",
    "- $ \\theta \\leftarrow \\operatorname{OptimizerStep}(\\theta, \\nabla_{\\theta}L^m) $\n",
    "\n",
    "De esta forma la influencia en el error cometido se aplica segmento a segmento, sin propagar el error a través de todos los segmentos, y actuando como un mecanismo de regularización que tiene en cuenta únicamente las activaciones más recientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dcf610-1e94-4921-8ba3-185aebba8bcd",
   "metadata": {},
   "source": [
    "### 3.3. Adaptive Computational Time\n",
    "\n",
    "_HRM_ utiliza el algoritmo _Q-learning_ para determinar el número de segmentos a ejecutar.\n",
    "\n",
    "El número máximo $M_\\text{max}$ de segmentos se establece mediante un hiperparámetro del modelo. Y el número mínimo $M_\\text{min}$ de segmentos se determina estocásticamente en función de un hiperparámetro $\\epsilon$ del modelo. Para $\\epsilon$, $M_\\text{min}$ se establece tomando una muestra usando una distribución de probabilidad uniforme sobre el conjunto $\\{2, \\ldots, M_\\text{max}\\}$, y para $1 - \\epsilon$, $M_\\text{min}$ se establece a $1$.\n",
    "\n",
    "_Q-learning_ funciona en base a una tabla de estados y acciones que se pueden realizar sobre dichos estados. Los valores sobre la tabla determinan la calidad por la ejecución de cada acción en cada estado.\n",
    "\n",
    "_HRM_ define dos posibles acciones: \"_halt_\" (_parar_) y \"_continue_\" (_continuar_), y las recompensas para cada acción tras la ejecución de cada segmento $m$.\n",
    "\n",
    "- $ \\hat{G}^m = (\\hat{G}_\\text{halt}^m, \\hat{G}_\\text{continue}^m) $\n",
    "\n",
    "La acción \"_halt_\" termina la ejecución de segmentos, y proporciona una recompensa condicionada de $0$ ó $1$ en función de si la salida predicha se corresponde con la esperada.\n",
    "\n",
    "- $ \\hat{G}_\\text{halt}^m = \\textbf{1}\\{\\hat{y}^m = y\\} $\n",
    "\n",
    "La acción \"_continue_\" continúa con la ejecución del siguiente segmento, y proporciona una recompensa de $0$.\n",
    "\n",
    "- $ \\hat{G}_\\text{continue}^m = \\begin{cases}\n",
    "\\hat{Q}_\\text{halt}^{m+1} & \\text{si} & m \\ge M_{max},\n",
    "\\\\ \\operatorname{max}(\\hat{Q}_\\text{halt}^{m+1}, \\hat{Q}_\\text{continue}^{m+1}) & \\text{en} & \\text{caso contrario}.\n",
    "\\end{cases} $\n",
    "\n",
    "Lo que quiere decir la expresión es que la acción \"_halt_\" se selecciona cuando se alcanza $M_\\text{max}$ segmentos ejecutados, o $\\hat{Q}_\\text{halt}$ es mayor que $\\hat{Q}_\\text{continue}$, siempre y cuando se hayan ejecutado al menos $M_\\text{min}$ segmentos.\n",
    "\n",
    "Los valores $\\hat{Q}^m$ correspondientes a las dos posibles acciones se calculan utilizando el estado final del módulo _H_.\n",
    "\n",
    "- $ \\hat{Q}^m = (\\hat{Q}_\\text{halt}^m, \\hat{Q}_\\text{continue}^m) = \\sigma\\left(\\theta_Q^\\intercal z_H^{mNT}\\right) $\n",
    "\n",
    "Donde $\\theta_Q^\\intercal$ es la traspuesta de la matriz de pesos entrenable de la capa _Q-Head_ que implementa _Q-learning_, y $\\sigma$ la función sigmoide aplicada elemento a elemento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370dbadc-5c64-43d7-970c-64845d0e2cc4",
   "metadata": {},
   "source": [
    "### 3.4. Loss\n",
    "\n",
    "_HRM_ calcula la pérdida final para cada segmento teniendo en cuenta la pérdida calculada por el mecanismo de _deep supervision_ y la pérdida de la capa _Q-Head_.\n",
    "\n",
    "- $ L_\\text{ACT}^m = \\operatorname{LOSS}(\\hat{y}^m, y) + \\operatorname{BinaryCrossEntropy}(\\hat{Q}^m, \\hat{G}^m) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252b67a-6094-4ddb-82a2-2e30eb960c64",
   "metadata": {},
   "source": [
    "## 4. Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dda619-77a3-4462-822f-c464f38f6e0d",
   "metadata": {},
   "source": [
    "### 4.1. sequence-to-sequence\n",
    "\n",
    "```\n",
    "Input ─> I ─> L ─> H ─> O ─> Output\n",
    "```\n",
    "\n",
    "El modelo se implementa como una arquitectura _sequence-to-sequence_ que recibe una secuencia de _tokens_ $x$ de longitud $l$ y emite una secuencia de _tokens_ $y$ de longitud $l'$.\n",
    "\n",
    "- $ x = (x_1, \\ldots, x_l) $\n",
    "\n",
    "- $ y = (y_1, \\ldots, y_{l'}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33323c-0e48-4f44-9f3e-1e85ae5600aa",
   "metadata": {},
   "source": [
    "### 4.2. Input Network\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> L ─> H ─> O ─> Output\n",
    "```\n",
    "\n",
    "La red de entrada $f_I$ se implementa con una capa de _embedding_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582d8c7f-c0df-41fa-86f8-aaac7f8d26ca",
   "metadata": {},
   "source": [
    "### 4.3. Recurrent Modules\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> Transformer ─> Transformer ─> O ─> Output\n",
    "```\n",
    "\n",
    "Los dos módulos recurrentes se implementan como _encoders_, ambos siguiendo la misma arquitectura _Transformer_, con las mismas dimensiones.\n",
    "\n",
    "Los estados internos $z$ son inicializados tomando muestras con una distribución normal de media $0$ y desviación típica $1$ dentro del rango $[-2, 2]$.\n",
    "\n",
    "Y la implementación utiliza las técnicas más habituales en desarrollos actuales como _Rotary Positional Encoding_, _Gated Linear Units_, _RMSNorm_, y prescinde de los términos de _bias_ en las capas lineales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa497ef1-e1b6-4ab8-9b1d-717616d12e41",
   "metadata": {},
   "source": [
    "### 4.4. Output Network\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> Transformer ─> Transformer ─> SoftMax ─> Output\n",
    "```\n",
    "\n",
    "La red de salida $f_O$ se implementa aplicando la función $\\operatorname{softmax}$.\n",
    "\n",
    "- $ f_O(z; \\theta_O) = \\operatorname{softmax}(\\theta_O z) $\n",
    "\n",
    "O alternativamente la función $\\operatorname{stablemax}$ para experimentos con un número reducido de muestras de entrenamiento.\n",
    "\n",
    "- $ \\operatorname{stablemax}(x_i) = \\dfrac{s(x_i)}{\\sum\\limits_j s(x_j)} $\n",
    "\n",
    "Siendo:\n",
    "\n",
    "- $ s(x) = \\begin{cases}\n",
    "x + 1 & \\text{si} & x \\ge 0,\n",
    "\\\\ \\dfrac{1}{1 - x} & \\text{si} & x < 0.\n",
    "\\end{cases} $\n",
    "\n",
    "La salida es la distribución de probabilidad $\\hat{y}$ calculada mediante $softmax$ a partir de los estados internos $z$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c7840-ad36-4726-a49a-ba06179cacc8",
   "metadata": {},
   "source": [
    "### 4.5. Loss\n",
    "\n",
    "```\n",
    "Input ─> Embedding ─> Transformer ─> Transformer ─> SoftMax ─> Loss ─> Output\n",
    "```\n",
    "\n",
    "La pérdida a la salida de la red se calcula promediando para todos los _tokens_ de la secuencia de salida.\n",
    "\n",
    "- $ \\operatorname{LOSS}(\\hat{y}, y) = \\dfrac{1}{l'} \\sum\\limits_{i=1}^{l'} \\log p(y_i) $\n",
    "\n",
    "Siendo $p(y_i)$ la probabilidad que la distribución de salida $\\hat{y}_i$ asigna al _token_ $y_i$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
